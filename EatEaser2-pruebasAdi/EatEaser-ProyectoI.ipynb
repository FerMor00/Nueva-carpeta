{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8318545",
   "metadata": {},
   "source": [
    "<div style='width=100%; display:flex;flex-direction:row'><img  src=https://universidadeuropea.com/resources/media/images/universidad-europea-logo_poc9mEM.original.png width=100  style='  margin-left: auto;margin-right: auto; width: 25%; height:25%;'><img  src=https://i.ibb.co/1068C7j/EATEASER.jpg width=100 style='  margin-left: auto;margin-right: auto; width: 10%;height:25%;'></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ee9dce",
   "metadata": {},
   "source": [
    "<div style='margin:auto;text-align: center;font-family: \"Times New Roman\", Times, serif; font-weight: bold;'>PROYECTO COMUTACIONAL<br><br>EATEASER - VOZ A TEXTO</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c329ef59",
   "metadata": {},
   "source": [
    "<div style='width:100%; display:flex;flex-direction:row'>\n",
    "    <div style='width:50%;margin-right:5cm;'>\n",
    "        <p style='font-family: \"Times New Roman\", Times, serif; font-weight: bold;'>ESTUDIANTES</p>\n",
    "<ul style='font-family: \"Times New Roman\", Times, serif;'>\n",
    "    <li>Adilem Dobras 21911633</li><li>Roberto Echevarria 21823680</li><li>Carlos Gonzales 22067726</li><li>Juan Carlos Rondeau 21816176</li></ul> </div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3dfd23",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 19px;color:#6DA0FF;font-family:Georgia, Times, 'Times New Roman', serif;letter-spacing: 3px;font-weight: normal\">1. Importamos las librerias</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e13fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pitu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pitu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\pitu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pathlib\n",
    "import sys\n",
    "import logging\n",
    "import json\n",
    "import joblib\n",
    "import warnings\n",
    "import math\n",
    "import random\n",
    "import multiprocessing\n",
    "from random import shuffle\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ModuleNotFoundError:\n",
    "    !pip install pandas\n",
    "    import pandas as pd\n",
    "try:\n",
    "    from pytube import YouTube\n",
    "    from pytube import Playlist\n",
    "except ModuleNotFoundError:\n",
    "    !pip install pytube\n",
    "    from pytube import YouTube\n",
    "    from pytube import Playlist\n",
    "try:\n",
    "    import speech_recognition as sr\n",
    "except ModuleNotFoundError:\n",
    "    !pip install SpeechRecognition\n",
    "    import speech_recognition as sr\n",
    "try:\n",
    "    from pydub import AudioSegment\n",
    "    from pydub.silence import split_on_silence\n",
    "except:\n",
    "    !pip install pydub\n",
    "    from pydub import AudioSegment\n",
    "    from pydub.silence import split_on_silence\n",
    "try:\n",
    "    import moviepy.editor as mp\n",
    "except:\n",
    "    !pip install moviepy\n",
    "    import moviepy.editor as mp\n",
    "try:\n",
    "    from bs4 import BeautifulSoup\n",
    "except:\n",
    "    !pip install beautifulsoup4\n",
    "    from bs4 import BeautifulSoup\n",
    "try:\n",
    "    from nltk.stem import PorterStemmer\n",
    "    from nltk.tokenize import word_tokenize\n",
    "except:\n",
    "    !pip install nltk\n",
    "    from nltk.stem import PorterStemmer\n",
    "    from nltk.tokenize import word_tokenize\n",
    "try:\n",
    "    import pyrebase\n",
    "except:\n",
    "    !pip install pyrebase4\n",
    "    import pyrebase\n",
    "try:   \n",
    "    import nltk\n",
    "    #nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem.rslp import RSLPStemmer\n",
    "    nltk.download('rslp')\n",
    "except:\n",
    "    !pip install nltk\n",
    "    import nltk\n",
    "    #nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem.rslp import RSLPStemmer\n",
    "    nltk.download('rslp')\n",
    "try:\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.model_selection import ParameterGrid\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn import svm\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.datasets import make_blobs\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.model_selection import KFold\n",
    "except ModuleNotFoundError:\n",
    "    !pip install scikit-learn\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.model_selection import ParameterGrid\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn import svm\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.datasets import make_blobs\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.model_selection import KFold\n",
    "try:\n",
    "    import numpy as np\n",
    "    from scipy import stats\n",
    "except ModuleNotFoundError:\n",
    "    !pip install numpy\n",
    "    import numpy as np\n",
    "    from scipy import stats\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "except ModuleNotFoundError:\n",
    "    !pip install tensorflow\n",
    "    import tensorflow as tf\n",
    "try:\n",
    "    from keras.models import Sequential\n",
    "    from keras import layers\n",
    "except ModuleNotFoundError:\n",
    "    !pip install keras\n",
    "    from keras.models import Sequential\n",
    "    from keras import layers\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except ModuleNotFoundError:\n",
    "    !pip install matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except ModuleNotFoundError:\n",
    "    !pip install seaborn\n",
    "    import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bce916",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 19px;color:#6DA0FF;font-family:Georgia, Times, 'Times New Roman', serif;letter-spacing: 3px;font-weight: normal\">2. Inicio del programa</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f5340a",
   "metadata": {},
   "source": [
    "<h3  style='font-family: \"Times New Roman\", Times, serif; font-weight: bold;text-align:center;font-size:14px'>CLASE CONTROLADORVIDEO</h3><p style='font-family: \"Times New Roman\", Times, serif; font-size:14px'>En esta clase se realizar√° los ajustes para manejar el video recibido y manipularlo.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb88615",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ControladorVideo:\n",
    "    def __init__(self,enlace): \n",
    "        fb=Firebase('Interfaz/recetastextos/')\n",
    "        self._idvideo = fb.reenumerar()\n",
    "        self.enlacevideo=enlace\n",
    "        self.yt=YouTube(self.enlacevideo)\n",
    "        self.nombrevideo=''\n",
    "        self.titulovideo=self.yt.title\n",
    "        self.autorvideo=self.yt.author\n",
    "        self.fechavideo=self.yt.publish_date\n",
    "        self.duracionvideo=self.yt.length\n",
    "        self.rec=RecursosAdicionales()\n",
    "    \"\"\"|DESCARGAR VIDEO URL: descarga el video de youtube\n",
    "       |return: devuelve una ruta absoluta\"\"\"\n",
    "    def descargarVideoURL(self):\n",
    "        recetasVideos = 'recetasvideos/'\n",
    "        #aqui creo un nuevo id para el nuevo video\n",
    "        self._idvideo= self._idvideo+1\n",
    "        #esta sera el archivo del video y su nuevo nombre\n",
    "        nombre='receta'+str(self._idvideo)\n",
    "        #le pedimos al pytube que solo nos descargue el audio y lo descargamos\n",
    "        t=self.yt.streams.filter(file_extension='mp4').first().download(output_path=recetasVideos,filename=nombre+'.mp4')\n",
    "        #devolvemos el nombre\n",
    "        return nombre\n",
    "    \"\"\"|PARSEO VIDEO: pasa el video de .mp4 a .wav\n",
    "       |nombre: es un string que se colocara el nombre del video\n",
    "       |return: devuelve el nuevo nombre del audio en .wav\"\"\"\n",
    "    def parseoVideo(self,nombre):\n",
    "        recetasVideos = 'recetasvideos/'\n",
    "        #tomamos el video en mp4 \n",
    "        track = mp.VideoFileClip(recetasVideos+nombre+'.mp4')\n",
    "        #cambiamos el video a .wav\n",
    "        nombre_wav=\"{}.wav\".format(nombre)\n",
    "        track.audio.write_audiofile(recetasVideos+nombre_wav)\n",
    "        track.close()\n",
    "        return nombre\n",
    "    \"\"\"|SPEECH TEXT:Transforma el audio a texto\n",
    "       |nombre: es un string que se colocara el nombre del video\n",
    "       |return: devuelve un string con el texto devuelto\"\"\"\n",
    "    def speech_text(self,nombre):\n",
    "        recetasVideos = 'recetasvideos/'\n",
    "        #instanciamos el recognizer\n",
    "        r = sr.Recognizer()\n",
    "        audio = sr.AudioFile(recetasVideos+nombre)\n",
    "        with audio as source:\n",
    "            audio_file = r.record(source)\n",
    "        #transcribimos el audio a texto\n",
    "        result = r.recognize_google(audio_file, language = 'es-ES')\n",
    "        return result\n",
    "    def data_json(self):\n",
    "        return {\"id\":self._idvideo, \"nombre\":self.titulovideo, \"autor\": self.autorvideo, \"fecha\":str(self.fechavideo),\"enlace\":str(self.enlacevideo)}\n",
    "    def indexar_datos(self):\n",
    "        return self.rec.indexar_datos(\"Interfaz/recetastextos/indice.json\",{\"id\":self._idvideo+1, \"nombre\":self.titulovideo, \"autor\": self.autorvideo, \"fecha\":str(self.fechavideo),\"enlace\":str(self.enlacevideo)})\n",
    "    \"\"\"|REPETIDO:Nos dice si el video ya se encuentra en nuestra bd\n",
    "       |fileName: nombre del json\n",
    "       |key: llave en donde queremos encontrar lo que buscamos\n",
    "       |buscar: elemento que estamos buscando\"\"\"\n",
    "    def repetido(self):\n",
    "        return self.rec.buscar_json('Interfaz/recetastextos/indice.json','nombre',self.titulovideo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b297ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3  style='font-family: \"Times New Roman\", Times, serif; font-weight: bold;text-align:center;font-size:14px'>CLASE DEPURADOR</h3><p style='font-family: \"Times New Roman\", Times, serif; font-size:14px'>En esta clase se realizar√° el proceso de extraccion, transformacion y carga de nuestro programa EATEASER.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0598a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#si el video es mayor de 3 minutos no funciona\n",
    "#si el video es en ingles no funciona\n",
    "class Depurador:\n",
    "    \n",
    "    def __init__(self): \n",
    "        self.rec=RecursosAdicionales()\n",
    "    \"\"\"|VIDEO: proceso etl donde extraemos al informacion del video \n",
    "       |enlace: es un string que se colocara el enlace del video\"\"\"\n",
    "    def filtroDescarga(self, enlace_txtbox):\n",
    "        if(re.search(\"\\/playlist\\?\", enlace_txtbox)):\n",
    "            self.lista(enlace_txtbox)\n",
    "        else:\n",
    "            self.video(enlace_txtbox)\n",
    "    def video(self,enlace):\n",
    "        try:\n",
    "            #instanciamos el controlador de videos\n",
    "            cv=ControladorVideo(enlace)\n",
    "            fb=Firebase('Interfaz/recetastextos/')\n",
    "            \n",
    "            #paso 1: verificamos si existe en la database\n",
    "            if fb.validar_database(cv.titulovideo)==False:\n",
    "                #paso 2: guardamos en database datos principales\n",
    "                \n",
    "                #paso 3: descargamos el video\n",
    "                cv.nombrevideo=cv.descargarVideoURL()\n",
    "                print(\"id: \"+str(cv._idvideo))\n",
    "                fb.guardar_database(cv.data_json(),cv._idvideo)\n",
    "                #paso 4: pasamos el video a .wav\n",
    "                nombre=cv.parseoVideo(cv.nombrevideo)\n",
    "                #paso 5: evaluamos los silencios \n",
    "                try:                \n",
    "                    num_segm=self.rec.segcionarXsilencios(nombre)\n",
    "                    result=\"\"\n",
    "                    for i in range(num_segm):\n",
    "                        try:\n",
    "                            result=result+str(cv.speech_text(\"../temp_audios/{}_extracto{}.wav\".format(nombre,i+1)))\n",
    "                            result=result+\" \"\n",
    "                        except BaseException:\n",
    "                            logging.exception(\"An exception was thrown!\")\n",
    "                            audio1=AudioSegment.from_wav(\"temp_audios/{}_extracto{}.wav\".format(nombre,i+1))\n",
    "                            duracion=audio1.duration_seconds\n",
    "                            if duracion<=5:\n",
    "                                print(\"El extracto {} es un silencio\".format(i+1))\n",
    "                            elif duracion<=180:\n",
    "                                print(\"El extracto {} es m√∫sica o ruido\".format(i+1))\n",
    "                            else:\n",
    "                                print(\"Error importante en el extracto {}\".format(i+1))\n",
    "                    #paso 6: borramos los chunks temporales de audio\n",
    "                    self.rec.eliminacion_audio(\"temp_audios\",\"wav\")\n",
    "                    try:\n",
    "                        quitarEmojis = dict.fromkeys(range(0x10000, sys.maxunicode + 1), 'NULL')\n",
    "                        tituloSinEmojis=cv.titulovideo.translate(quitarEmojis)\n",
    "                        autorSinEmojis=cv.autorvideo.translate(quitarEmojis)\n",
    "                        #paso 7: escribimos el texto recibido en un txt->se guarda en local\n",
    "                        resultado=self.rec.escritura(cv.nombrevideo,\"Titulo:\"+tituloSinEmojis+\"\\n\"+\"Autor:\"+autorSinEmojis+\"\\n\"+\"Fecha Publicacion:\"+str(cv.fechavideo)+\"\\n\"+\"Enlace: \"+str(cv.enlacevideo)+\"\\n\"+\"Entradilla:\"+result)\n",
    "                        #paso 8: guardamos el texto en una base de datos\n",
    "                        fb.guardar_firebase(cv.nombrevideo+'.txt')\n",
    "                        #paso 9: eliminamos los mp4\n",
    "                        self.rec.eliminacion_audio(\"recetasvideos\",\"mp4\")\n",
    "                    except BaseException:\n",
    "                        logging.exception(\"An exception was thrown!\")\n",
    "                        print(\"No se ha podido eliminar los caracteres corruptos el video: \"+ cv.nombrevideo + \" - \"+ cv.titulovideo)\n",
    "                        self.rec.eliminacion_audio(\"recetasvideos\",\"mp4\")\n",
    "                        return None   \n",
    "                except BaseException:\n",
    "                    logging.exception(\"An exception was thrown!\")\n",
    "                    print(\"No se ha podido transcribir el video: \"+ cv.nombrevideo + \" - \"+ cv.titulovideo+\" - \"+cv.enlacevideo)\n",
    "                    self.rec.eliminacion_audio(\"recetasvideos\",\"mp4\")\n",
    "                    self.rec.eliminacion_audio(\"temp_audios\",\"wav\")\n",
    "                    return None\n",
    "            else:\n",
    "                print('Este video se encuentra en la base de datos.')\n",
    "                resultado=\"\"\n",
    "            return resultado\n",
    "        except BaseException:\n",
    "            logging.exception(\"An exception was thrown!\")\n",
    "            print(\"No se ha podido descargar el video: \"+ cv.nombrevideo + \" - \"+ cv.titulovideo)\n",
    "            return None\n",
    "    def lista(self, enlace):\n",
    "        playlist_urls = Playlist(enlace)\n",
    "        for url in playlist_urls:\n",
    "            self.video(url)\n",
    "    def transformacion(self):\n",
    "        print()\n",
    "    def carga(self):\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c910592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aqui iran lecturas-escrituras-guardar-eliminar cosas en bases de datos\n",
    "class RecursosAdicionales:\n",
    "    \"\"\"|ESCRITURA: escribe textos txt\n",
    "       |nombre: nombre del \n",
    "       |return: devuelve el audio en texto\"\"\"    \n",
    "    def escritura(self,nombre,texto):\n",
    "        recetasTextos = './Interfaz/recetastextos/'\n",
    "        if not(os.path.exists(recetasTextos)):\n",
    "            os.mkdir(recetasTextos)\n",
    "        f = open(recetasTextos+nombre+'.txt', 'w')\n",
    "        f.write(texto)\n",
    "        f = open(recetasTextos+nombre+'.txt', \"r\")\n",
    "        print(f.read())\n",
    "        f.close()\n",
    "        \n",
    "    def lectura_json(self,fileName):\n",
    "        if self.documento_vacio(fileName):\n",
    "            with open(fileName, \"r\") as file:\n",
    "                    archivo=json.load(file)\n",
    "        else: \n",
    "            archivo=[]\n",
    "            print('El documento se encuentra vacio.')\n",
    "        return archivo\n",
    "    \n",
    "    def escritura_json(self,fileName,data):\n",
    "        with open(fileName, \"w\") as file:\n",
    "                json.dump(data, file)\n",
    "                file.close()\n",
    "    def buscar_json(self,fileName,key,buscar):\n",
    "        encontrado=False\n",
    "        if self.documento_vacio(fileName):\n",
    "            archivo_json=self.lectura_json(fileName)\n",
    "            for item in archivo_json:\n",
    "                if buscar in item[key]:\n",
    "                    print('encontrado')\n",
    "                    encontrado=True\n",
    "                    #no me gusta usar esto pero no tengo idea de como usar un while con json\n",
    "                    break\n",
    "        return encontrado\n",
    "    def documento_vacio(self,fileName):\n",
    "        return os.stat(fileName).st_size != 0\n",
    "    def indexar_datos(self,fileName,adicion):\n",
    "        if not(os.path.exists(fileName)):\n",
    "            os.mkdir(fileName)\n",
    "        data=[]\n",
    "        data=self.lectura_json(fileName)\n",
    "        data.append(adicion)\n",
    "        self.escritura_json(fileName,data)\n",
    "        \n",
    "    def eliminacion_audio(self,path,tipo):\n",
    "        url = './'+path+'/'\n",
    "        py_files = glob.glob(url+'*.'+tipo)\n",
    "        for py_file in py_files:\n",
    "            try:\n",
    "                os.remove(py_file)\n",
    "            except OSError as e:\n",
    "                print(f\"Error:{ e.strerror}\")\n",
    "    \n",
    "    def segcionarXsilencios(self,audio):\n",
    "        audio1=AudioSegment.from_wav(\"./recetasvideos/\"+audio+\".wav\")\n",
    "        var_min=1900\n",
    "        salir=False\n",
    "        while salir==False:\n",
    "            samples = audio1.get_array_of_samples()\n",
    "            segundo=88521\n",
    "            index=[]\n",
    "            for i in range(0,len(samples),int(segundo/5)):\n",
    "                dataSeg = samples[i:int(segundo/5)+i]\n",
    "                media=np.mean(dataSeg)\n",
    "                var=np.var(dataSeg)\n",
    "                if -10<=media<=10 and var<=var_min:\n",
    "                    index.append(i)\n",
    "\n",
    "            borrar=[]\n",
    "            guardado=0\n",
    "            for i in range(len(index)-1):\n",
    "                if index[i+1]<=index[i]+(20*segundo):\n",
    "                    if i==0:\n",
    "                        tiempo=(index[i])/segundo\n",
    "                    else:\n",
    "                        tiempo=(index[i+1]-guardado)/segundo\n",
    "                    if tiempo<=120:\n",
    "                        borrar.append(i)\n",
    "                    else:\n",
    "                        guardado=index[i]\n",
    "                else:\n",
    "                    guardado=index[i]\n",
    "\n",
    "            final=np.delete(index, borrar, axis=0) \n",
    "            extractos=[]\n",
    "            if len(final)==0:\n",
    "                var_min=var_min*10\n",
    "                salir=False\n",
    "            else:\n",
    "                for i in range(len(final)):\n",
    "                    if i==0:\n",
    "                        extractos.append(samples[:final[i]])\n",
    "                    else:\n",
    "                        extractos.append(samples[final[i-1]:final[i]])\n",
    "                extractos.append(samples[final[i]:])\n",
    "                salir=True\n",
    "\n",
    "        for i in range(len(extractos)):\n",
    "            nombre=\"\"\n",
    "            new_sound = audio1._spawn(extractos[i])\n",
    "            nombre=\"temp_audios/{}_extracto{}.wav\".format(audio,i+1)\n",
    "            new_sound.export(nombre,format=\"wav\")\n",
    "        #print(len(extractos))\n",
    "        return len(extractos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "131f35f6-ac5b-4c99-88a3-e47d738b6a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Firebase:\n",
    "    def __init__(self,ubicacion):\n",
    "        self.ubi=ubicacion\n",
    "        \n",
    "        self.config={\"apiKey\": \"AIzaSyDDg9WOlFJxnEJoxomYtsnkJfsI4TgoL_E\",\"authDomain\": \"eateaser-741d4.firebaseapp.com\",\"databaseURL\" : \"https://eateaser-741d4-default-rtdb.firebaseio.com/\",\"projectId\": \"eateaser-741d4\",\"storageBucket\": \"eateaser-741d4.appspot.com\",\"messagingSenderId\": \"706351391410\",\"appId\": \"1:706351391410:web:6abc2cabd6bf83843b5fab\",\"measurementId\": \"G-YZZCBRHNBT\"};\n",
    "        self.firebase=self.conexion_firebase()\n",
    "        self.database=self.firebase.database()\n",
    "    def conexion_firebase(self):\n",
    "        return pyrebase.initialize_app(self.config)\n",
    "    def guardar_firebase(self,nom):\n",
    "        storage=self.firebase.storage()\n",
    "        storage.child(self.ubi+nom).put(self.ubi+nom)\n",
    "    def eliminar_firebase(self,nom):\n",
    "        self.firebase.storage().delete(self.ubi+nom)\n",
    "    def guardar_database(self,data,_id):\n",
    "        self.database.child('Recetas').child(_id).set(data)\n",
    "    def validar_database(self,data):\n",
    "        validar=self.database.get()\n",
    "        encontrado=False\n",
    "        for a in validar.each():\n",
    "            if  data in str(a.val()):\n",
    "                encontrado=True\n",
    "                #no me gusta usar esto pero no tengo idea de como usar un while con json\n",
    "                break\n",
    "        return encontrado\n",
    "    def reenumerar(self):\n",
    "        recetas=self.database.child(\"Recetas\").get()\n",
    "        id=0\n",
    "        for item in recetas.each():\n",
    "            id=item.key()\n",
    "        return int(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e747077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScrap:\n",
    "    def __init__(self): \n",
    "        self.headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    def request(self, url):\n",
    "        request1 = requests.get(url, headers=self.headers)\n",
    "        html = request1.content\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        return soup\n",
    "    def verificar_alimento(self,alimento):\n",
    "        soup = self.request( 'https://www.themealdb.com/api/json/v1/1/search.php?s='+alimento)\n",
    "        print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f517c7a4",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 19px;color:#6DA0FF;font-family:Georgia, Times, 'Times New Roman', serif;letter-spacing: 3px;font-weight: normal\">3. Main</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab0f882",
   "metadata": {},
   "source": [
    "#y si tambien vemos si le permitimos al usuario que meta videos?\n",
    "dep=Depurador()\n",
    "if __name__ == '__main__':\n",
    "    #dep.video('https://www.youtube.com/watch?v=6PzQY1E2s2g&list=PLxHmjpcgU5ArC2rY5cpoIcZoVKB_0UHfR&ab_channel=PlatosF%C3%A1cilesconTamara')\n",
    "    #dep.video('https://www.youtube.com/watch?v=PsqR5M8rdjA&list=LL&index=9&t=4s')\n",
    "    #dep.video('https://www.youtube.com/watch?v=xfYcM_jHgPY')\n",
    "    #dep.video('https://www.youtube.com/watch?v=wiCfqc5W-yo')\n",
    "    #error_nuevo#dep.video('https://www.youtube.com/watch?v=3DnPkf9rP_0')\n",
    "    #error_nuevo#dep.video('https://www.youtube.com/watch?v=xVsgKMZFCZY')\n",
    "    #dep.video('https://www.youtube.com/watch?v=rpCe0RPMY94')\n",
    "    #dep.video('https://www.youtube.com/watch?v=rv4gLMa-FYk')\n",
    "    #dep.video('https://www.youtube.com/watch?v=VS8zYxBj4r8')\n",
    "    #dep.video('https://www.youtube.com/watch?v=o99JXrEkZoo')\n",
    "    #dep.video('https://www.youtube.com/watch?v=lKkg5L23b3M')\n",
    "    #dep.video('https://www.youtube.com/watch?v=PsqR5M8rdjA&t=14s')\n",
    "    #dep.video('https://www.youtube.com/watch?v=IvZaAL6qYe0&t=29s')\n",
    "    #dep.video('https://www.youtube.com/watch?v=SIMQBuuyE9M')\n",
    "    #dep.video('https://www.youtube.com/watch?v=_YoZfg7R8Hk')\n",
    "    #dep.video('https://www.youtube.com/watch?v=Zv7KdlOBk7Y')\n",
    "    #dep.video('https://www.youtube.com/watch?v=mFcN4btaZyI&t=2s')\n",
    "    #dep.video('https://www.youtube.com/watch?v=sRmmQBBln9Q')\n",
    "    #dep.video('https://www.youtube.com/watch?v=-QoTJJJfeEE')\n",
    "    #dep.video('https://www.youtube.com/watch?v=JRY5obPKPzo&list=PLxHmjpcgU5ArC2rY5cpoIcZoVKB_0UHfR&index=5&ab_channel=PlatosF%C3%A1cilesconTamara')\n",
    "    #dep.video('https://www.youtube.com/watch?v=stFmx7OCy1k&ab_channel=RecetasdeEsbieta')\n",
    "    #error_videomuylargo#dep.video(\"https://www.youtube.com/watch?v=qqTqePGIjhc\")\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLQwfLPYiFlOsS9x6zgeZmFRLqDx3poZvw\")\n",
    "    #dep.lista(\"https://www.youtube.com/playlist?list=PLIsSIvqffHZvM2v1QS5Zi0MUL258EKLPq\")\n",
    "    #dep.video('https://www.youtube.com/watch?v=rv4gLMa-FYk')\n",
    "    \n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLf2b-1EmxBEcmcj5GPFfFMbvegVKFOIYR\")\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PL2rWPa7BVMtzadghDZ7cHbkXuJ735RVnZ\")\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLiIutYe2uQJrwuRzF0_8tf_a651emeOiO\")\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLEOkiu1MfX7FsiTlZfaHZtMfo1EZD96tq\")\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PL8Vs-hI7gkl0yY6T0qbWSsw_Zv9d2cqnu\")#arroces\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PL8Id0yl_4Lo-AtOvrizH3OA6yOK0HLRPw\")#mariscos\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLxHmjpcgU5Apmx0uz4mfhWZmMFrIm-1a8\")#pasta **\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLxHmjpcgU5AqiG1XoX00meJj9rnNIp9qT\")#carnes\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLgDn1_a8qclShfo0yvUUPrX673yC3v8LR\")#pescados y algun marisco\n",
    "    #No acabada # dep.lista(\"https://youtube.com/playlist?list=PLge9wrsFXyuYHweFYpDMnHp95WYe6Prfn\")#verduras\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PL1DDoU1JPaGI0ZVkGbXPhUq2ttCVPBKc5\")#arroces\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PL75JfQSBdGa9ez55vz1evAkKtI_e8SzCh\")\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PL75JfQSBdGa9RP3HprHJHyLMmM2hC9uu7\")#marisco\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLNvWgJIx6X41jbPxHH0h6I_JJimIKzlVF\")#pasta\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLcPdHx9MSg_DAHTy258b0F1vdZE7nRHYX\")#pescado\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLWwMSMcUrXKFkBuQfR0uNB7E8TL7dnmfY\")#platosMenores\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLdLEn2GksKhaCS9QmsKaHcC4Yr6jCKHf_\")#verduras\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLoNzD53SxXZC84LG74DVYvqYCSwMaVIKn\")#platosMenores\n",
    "    #dep.lista(\"https://youtube.com/playlist?list=PLUxqTjTdTvkN2JpDMcTKcMxEGZqmJ14Xu\")#platosMenores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cfa42e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0./Interfaz/recetastextos/Carpeta Arroz/-----------------\n",
      "['receta108.txt', 'receta12.txt', 'receta125.txt', 'receta133.txt', 'receta134.txt', 'receta139.txt', 'receta1549.txt', 'receta1550.txt', 'receta1561.txt', 'receta1583.txt', 'receta1584.txt', 'receta1586.txt', 'receta1593.txt', 'receta1596.txt', 'receta160.txt', 'receta1610.txt', 'receta1611.txt', 'receta1618.txt', 'receta1620.txt', 'receta1621.txt', 'receta1629.txt', 'receta163.txt', 'receta1635.txt', 'receta165.txt', 'receta1654.txt', 'receta1655.txt', 'receta1656.txt', 'receta1657.txt', 'receta1658.txt', 'receta1666.txt', 'receta1667.txt', 'receta1668.txt', 'receta1669.txt', 'receta1670.txt', 'receta1671.txt', 'receta171.txt', 'receta172.txt', 'receta173.txt', 'receta174.txt', 'receta175.txt', 'receta177.txt', 'receta200.txt', 'receta358.txt', 'receta359.txt', 'receta360.txt', 'receta363.txt', 'receta364.txt', 'receta365.txt', 'receta366.txt', 'receta367.txt', 'receta368.txt', 'receta374.txt', 'receta376.txt', 'receta379.txt', 'receta386.txt', 'receta388.txt', 'receta389.txt', 'receta390.txt', 'receta391.txt', 'receta392.txt', 'receta393.txt', 'receta394.txt', 'receta395.txt', 'receta396.txt', 'receta397.txt', 'receta398.txt', 'receta400.txt', 'receta401.txt', 'receta402.txt', 'receta405.txt', 'receta406.txt', 'receta407.txt', 'receta410.txt', 'receta411.txt', 'receta412.txt', 'receta416.txt', 'receta417.txt', 'receta422.txt', 'receta429.txt', 'receta84.txt', 'receta90.txt']\n",
      "1./Interfaz/recetastextos/Carpeta Bebidas/-----------------\n",
      "['receta1674.txt', 'receta1675.txt', 'receta1676.txt', 'receta1677.txt', 'receta1678.txt', 'receta1679.txt', 'receta1680.txt', 'receta1681.txt', 'receta1682.txt', 'receta1683.txt', 'receta1684.txt', 'receta1685.txt', 'receta1686.txt', 'receta1687.txt', 'receta1688.txt', 'receta1689.txt', 'receta1690.txt', 'receta1691.txt', 'receta1692.txt', 'receta1693.txt', 'receta1694.txt', 'receta1695.txt', 'receta1696.txt', 'receta1697.txt', 'receta1698.txt', 'receta1699.txt', 'receta1700.txt', 'receta1701.txt', 'receta1702.txt', 'receta1703.txt', 'receta1704.txt', 'receta1705.txt', 'receta1706.txt', 'receta1707.txt', 'receta1708.txt', 'receta1709.txt', 'receta1710.txt', 'receta1711.txt', 'receta1712.txt', 'receta1713.txt', 'receta1714.txt', 'receta1715.txt', 'receta1716.txt', 'receta1717.txt', 'receta1718.txt', 'receta1719.txt', 'receta1720.txt', 'receta1721.txt', 'receta1722.txt', 'receta1723.txt', 'receta1724.txt', 'receta1725.txt', 'receta1726.txt', 'receta1727.txt', 'receta1728.txt', 'receta1729.txt', 'receta1730.txt', 'receta1731.txt', 'receta1732.txt', 'receta1733.txt', 'receta623.txt', 'receta633.txt', 'receta634.txt', 'receta635.txt', 'receta636.txt', 'receta637.txt', 'receta638.txt', 'receta639.txt', 'receta640.txt', 'receta641.txt', 'receta642.txt', 'receta643.txt', 'receta644.txt', 'receta645.txt', 'receta646.txt', 'receta648.txt', 'receta649.txt', 'receta651.txt', 'receta652.txt', 'receta653.txt', 'receta654.txt', 'receta655.txt', 'receta656.txt', 'receta657.txt', 'receta658.txt', 'receta659.txt', 'receta660.txt', 'receta661.txt', 'receta662.txt', 'receta663.txt', 'receta664.txt', 'receta665.txt', 'receta666.txt', 'receta668.txt', 'receta669.txt', 'receta670.txt', 'receta671.txt', 'receta672.txt', 'receta674.txt', 'receta675.txt', 'receta676.txt', 'receta678.txt', 'receta679.txt', 'receta680.txt', 'receta681.txt', 'receta682.txt', 'receta683.txt', 'receta685.txt', 'receta686.txt', 'receta687.txt', 'receta688.txt', 'receta690.txt', 'receta692.txt', 'receta693.txt', 'receta694.txt', 'receta695.txt', 'receta696.txt', 'receta698.txt', 'receta700.txt', 'receta701.txt', 'receta702.txt', 'receta703.txt']\n",
      "2./Interfaz/recetastextos/Carpeta Carnes/-----------------\n",
      "['receta1.txt', 'receta1137.txt', 'receta1138.txt', 'receta1139.txt', 'receta114.txt', 'receta1140.txt', 'receta1141.txt', 'receta1142.txt', 'receta1143.txt', 'receta1144.txt', 'receta1145.txt', 'receta1146.txt', 'receta1147.txt', 'receta1148.txt', 'receta1149.txt', 'receta1150.txt', 'receta1151.txt', 'receta1152.txt', 'receta1153.txt', 'receta1154.txt', 'receta1155.txt', 'receta1156.txt', 'receta1157.txt', 'receta1158.txt', 'receta1159.txt', 'receta1160.txt', 'receta1161.txt', 'receta1162.txt', 'receta1163.txt', 'receta1164.txt', 'receta1165.txt', 'receta1166.txt', 'receta1167.txt', 'receta1168.txt', 'receta1169.txt', 'receta1170.txt', 'receta1171.txt', 'receta1172.txt', 'receta1173.txt', 'receta1174.txt', 'receta1175.txt', 'receta1176.txt', 'receta1177.txt', 'receta1178.txt', 'receta1179.txt', 'receta1180.txt', 'receta1181.txt', 'receta1182.txt', 'receta1183.txt', 'receta1184.txt', 'receta1185.txt', 'receta1186.txt', 'receta1187.txt', 'receta1188.txt', 'receta1189.txt', 'receta1190.txt', 'receta1191.txt', 'receta1192.txt', 'receta1193.txt', 'receta1194.txt', 'receta1195.txt', 'receta1196.txt', 'receta1197.txt', 'receta1198.txt', 'receta1199.txt', 'receta16.txt', 'receta1734.txt', 'receta1735.txt', 'receta1736.txt', 'receta1737.txt', 'receta1738.txt', 'receta1739.txt', 'receta1740.txt', 'receta1741.txt', 'receta1742.txt', 'receta1743.txt', 'receta1744.txt', 'receta1745.txt', 'receta1746.txt', 'receta1747.txt', 'receta1748.txt', 'receta1749.txt', 'receta1750.txt', 'receta1751.txt', 'receta1752.txt', 'receta1753.txt', 'receta1754.txt', 'receta1755.txt', 'receta1756.txt', 'receta1757.txt', 'receta1758.txt', 'receta1759.txt', 'receta1760.txt', 'receta1761.txt', 'receta1762.txt', 'receta1763.txt', 'receta1764.txt', 'receta1765.txt', 'receta1766.txt', 'receta1767.txt', 'receta1768.txt', 'receta1769.txt', 'receta1770.txt', 'receta1771.txt', 'receta1772.txt', 'receta1773.txt', 'receta1774.txt', 'receta1775.txt', 'receta1776.txt', 'receta1777.txt', 'receta1778.txt', 'receta1779.txt', 'receta1780.txt', 'receta1781.txt', 'receta1782.txt', 'receta1783.txt', 'receta1784.txt', 'receta1785.txt', 'receta1786.txt', 'receta1787.txt', 'receta1788.txt', 'receta1789.txt', 'receta1790.txt', 'receta1791.txt', 'receta1792.txt', 'receta1793.txt', 'receta1794.txt', 'receta1795.txt', 'receta1796.txt', 'receta1797.txt', 'receta1798.txt', 'receta1799.txt', 'receta1800.txt', 'receta1801.txt', 'receta1802.txt', 'receta1803.txt', 'receta1804.txt', 'receta1805.txt', 'receta1806.txt', 'receta1807.txt', 'receta1808.txt', 'receta1809.txt', 'receta1810.txt', 'receta1811.txt', 'receta1812.txt', 'receta1813.txt', 'receta1814.txt', 'receta1815.txt', 'receta1816.txt', 'receta1817.txt', 'receta1818.txt', 'receta1819.txt', 'receta1820.txt', 'receta1821.txt', 'receta1822.txt', 'receta1823.txt', 'receta1824.txt', 'receta1825.txt', 'receta1826.txt', 'receta1827.txt', 'receta1828.txt', 'receta1829.txt', 'receta1830.txt', 'receta1831.txt', 'receta1832.txt', 'receta1833.txt', 'receta1834.txt', 'receta1835.txt', 'receta1836.txt', 'receta1837.txt', 'receta1838.txt', 'receta1839.txt', 'receta1840.txt', 'receta1841.txt', 'receta1842.txt', 'receta1843.txt', 'receta1844.txt', 'receta1845.txt', 'receta1846.txt', 'receta1847.txt', 'receta1848.txt', 'receta1849.txt', 'receta1850.txt', 'receta1851.txt', 'receta1852.txt', 'receta1853.txt', 'receta1854.txt', 'receta1855.txt', 'receta1856.txt', 'receta1857.txt', 'receta1858.txt', 'receta1859.txt', 'receta1860.txt', 'receta1861.txt', 'receta1862.txt', 'receta1863.txt', 'receta1864.txt', 'receta1865.txt', 'receta1866.txt', 'receta1867.txt', 'receta1868.txt', 'receta1869.txt', 'receta1870.txt', 'receta1871.txt', 'receta1872.txt', 'receta1873.txt', 'receta1874.txt', 'receta1875.txt', 'receta1876.txt', 'receta1877.txt', 'receta1878.txt', 'receta1879.txt', 'receta1880.txt', 'receta1881.txt', 'receta1882.txt', 'receta1883.txt', 'receta1884.txt', 'receta1885.txt', 'receta1886.txt', 'receta1887.txt', 'receta1888.txt', 'receta1889.txt', 'receta209.txt', 'receta258.txt', 'receta259.txt', 'receta260.txt', 'receta261.txt', 'receta262.txt', 'receta263.txt', 'receta264.txt', 'receta266.txt', 'receta267.txt', 'receta268.txt', 'receta269.txt', 'receta270.txt', 'receta271.txt', 'receta272.txt', 'receta273.txt', 'receta274.txt', 'receta275.txt', 'receta276.txt', 'receta277.txt', 'receta278.txt', 'receta280.txt', 'receta281.txt', 'receta282.txt', 'receta283.txt', 'receta284.txt', 'receta285.txt', 'receta286.txt', 'receta287.txt', 'receta29.txt', 'receta3.txt', 'receta31.txt', 'receta32.txt', 'receta39.txt', 'receta42.txt', 'receta43.txt', 'receta48.txt', 'receta51.txt', 'receta58.txt', 'receta6.txt', 'receta63.txt', 'receta65.txt', 'receta71.txt', 'receta73.txt', 'receta77.txt', 'receta781.txt', 'receta782.txt', 'receta783.txt', 'receta784.txt', 'receta785.txt', 'receta786.txt', 'receta787.txt', 'receta788.txt', 'receta789.txt', 'receta790.txt', 'receta791.txt', 'receta792.txt', 'receta793.txt', 'receta794.txt', 'receta795.txt', 'receta796.txt', 'receta797.txt', 'receta798.txt', 'receta799.txt', 'receta8.txt', 'receta800.txt', 'receta801.txt', 'receta802.txt', 'receta803.txt', 'receta804.txt', 'receta805.txt', 'receta806.txt', 'receta807.txt', 'receta808.txt', 'receta809.txt', 'receta810.txt', 'receta811.txt', 'receta812.txt', 'receta83.txt', 'receta871.txt', 'receta872.txt', 'receta873.txt', 'receta874.txt', 'receta875.txt', 'receta876.txt', 'receta877.txt', 'receta878.txt', 'receta879.txt', 'receta880.txt', 'receta881.txt', 'receta882.txt', 'receta883.txt', 'receta884.txt', 'receta885.txt', 'receta886.txt', 'receta887.txt', 'receta888.txt', 'receta889.txt', 'receta890.txt', 'receta891.txt', 'receta892.txt', 'receta893.txt', 'receta894.txt', 'receta895.txt', 'receta896.txt', 'receta897.txt', 'receta898.txt', 'receta899.txt', 'receta900.txt', 'receta901.txt', 'receta902.txt', 'receta903.txt', 'receta904.txt', 'receta905.txt', 'receta906.txt', 'receta907.txt', 'receta908.txt', 'receta909.txt', 'receta910.txt', 'receta911.txt', 'receta912.txt', 'receta913.txt', 'receta914.txt', 'receta915.txt', 'receta916.txt', 'receta917.txt', 'receta918.txt', 'receta919.txt', 'receta920.txt', 'receta93.txt']\n",
      "3./Interfaz/recetastextos/Carpeta Marisco/-----------------\n",
      "['receta180.txt', 'receta184.txt', 'receta185.txt', 'receta195.txt', 'receta202.txt', 'receta203.txt', 'receta204.txt', 'receta205.txt', 'receta212.txt', 'receta213.txt', 'receta214.txt', 'receta216.txt', 'receta218.txt', 'receta219.txt', 'receta221.txt', 'receta224.txt', 'receta226.txt', 'receta26.txt', 'receta298.txt', 'receta306.txt', 'receta310.txt', 'receta319.txt', 'receta322.txt', 'receta330.txt', 'receta333.txt', 'receta334.txt', 'receta35.txt', 'receta41.txt', 'receta481.txt', 'receta486.txt', 'receta487.txt', 'receta491.txt', 'receta5.txt', 'receta501.txt', 'receta502.txt', 'receta505.txt', 'receta510.txt', 'receta515.txt', 'receta516.txt', 'receta517.txt', 'receta518.txt', 'receta520.txt', 'receta521.txt', 'receta522.txt', 'receta524.txt', 'receta525.txt', 'receta528.txt', 'receta532.txt', 'receta540.txt', 'receta541.txt', 'receta542.txt', 'receta544.txt', 'receta552.txt', 'receta602.txt', 'receta632.txt']\n",
      "4./Interfaz/recetastextos/Carpeta Pasta/-----------------\n",
      "['receta118.txt', 'receta120.txt', 'receta1200.txt', 'receta1201.txt', 'receta1202.txt', 'receta1203.txt', 'receta1204.txt', 'receta1205.txt', 'receta1206.txt', 'receta1207.txt', 'receta1208.txt', 'receta1209.txt', 'receta1210.txt', 'receta1211.txt', 'receta1212.txt', 'receta1213.txt', 'receta1214.txt', 'receta1215.txt', 'receta1216.txt', 'receta1217.txt', 'receta1218.txt', 'receta1219.txt', 'receta1220.txt', 'receta1221.txt', 'receta1222.txt', 'receta1223.txt', 'receta1224.txt', 'receta1225.txt', 'receta1226.txt', 'receta1227.txt', 'receta1228.txt', 'receta1229.txt', 'receta1230.txt', 'receta1231.txt', 'receta1232.txt', 'receta1233.txt', 'receta1234.txt', 'receta1235.txt', 'receta1236.txt', 'receta1237.txt', 'receta1238.txt', 'receta1239.txt', 'receta1240.txt', 'receta1241.txt', 'receta1242.txt', 'receta1243.txt', 'receta1244.txt', 'receta1245.txt', 'receta1246.txt', 'receta1247.txt', 'receta1248.txt', 'receta1249.txt', 'receta1250.txt', 'receta1251.txt', 'receta1252.txt', 'receta1253.txt', 'receta1254.txt', 'receta1255.txt', 'receta1256.txt', 'receta1257.txt', 'receta1258.txt', 'receta15.txt', 'receta1551.txt', 'receta1552.txt', 'receta1553.txt', 'receta1554.txt', 'receta1555.txt', 'receta1556.txt', 'receta1557.txt', 'receta1558.txt', 'receta1559.txt', 'receta1560.txt', 'receta1562.txt', 'receta1563.txt', 'receta1564.txt', 'receta1565.txt', 'receta1566.txt', 'receta1567.txt', 'receta1568.txt', 'receta1569.txt', 'receta1570.txt', 'receta1571.txt', 'receta1572.txt', 'receta1573.txt', 'receta1574.txt', 'receta1575.txt', 'receta1576.txt', 'receta1577.txt', 'receta1578.txt', 'receta1579.txt', 'receta1580.txt', 'receta1581.txt', 'receta1582.txt', 'receta1585.txt', 'receta1587.txt', 'receta1588.txt', 'receta1589.txt', 'receta1590.txt', 'receta1591.txt', 'receta1592.txt', 'receta1594.txt', 'receta1595.txt', 'receta1597.txt', 'receta1598.txt', 'receta1599.txt', 'receta1600.txt', 'receta1601.txt', 'receta1602.txt', 'receta1603.txt', 'receta1604.txt', 'receta1605.txt', 'receta1606.txt', 'receta1607.txt', 'receta1608.txt', 'receta1609.txt', 'receta1612.txt', 'receta1613.txt', 'receta1614.txt', 'receta1615.txt', 'receta1616.txt', 'receta1617.txt', 'receta1619.txt', 'receta1622.txt', 'receta1623.txt', 'receta1624.txt', 'receta1625.txt', 'receta1626.txt', 'receta1627.txt', 'receta1628.txt', 'receta1630.txt', 'receta1631.txt', 'receta1632.txt', 'receta1633.txt', 'receta1634.txt', 'receta1636.txt', 'receta1637.txt', 'receta1638.txt', 'receta1639.txt', 'receta1640.txt', 'receta1641.txt', 'receta1642.txt', 'receta1643.txt', 'receta1644.txt', 'receta1645.txt', 'receta1646.txt', 'receta1647.txt', 'receta1648.txt', 'receta1649.txt', 'receta1650.txt', 'receta1651.txt', 'receta1652.txt', 'receta1653.txt', 'receta1659.txt', 'receta1660.txt', 'receta1661.txt', 'receta1662.txt', 'receta1663.txt', 'receta1664.txt', 'receta1665.txt', 'receta1672.txt', 'receta1673.txt', 'receta228.txt', 'receta229.txt', 'receta230.txt', 'receta231.txt', 'receta232.txt', 'receta234.txt', 'receta235.txt', 'receta236.txt', 'receta237.txt', 'receta238.txt', 'receta239.txt', 'receta24.txt', 'receta240.txt', 'receta241.txt', 'receta242.txt', 'receta243.txt', 'receta244.txt', 'receta246.txt', 'receta247.txt', 'receta248.txt', 'receta249.txt', 'receta250.txt', 'receta252.txt', 'receta253.txt', 'receta254.txt', 'receta256.txt', 'receta257.txt', 'receta555.txt', 'receta556.txt', 'receta557.txt', 'receta558.txt', 'receta559.txt', 'receta56.txt', 'receta561.txt', 'receta563.txt', 'receta564.txt', 'receta566.txt', 'receta567.txt', 'receta568.txt', 'receta569.txt', 'receta570.txt', 'receta573.txt', 'receta574.txt', 'receta575.txt', 'receta576.txt', 'receta577.txt', 'receta578.txt', 'receta579.txt', 'receta580.txt', 'receta581.txt', 'receta582.txt', 'receta583.txt', 'receta584.txt', 'receta586.txt', 'receta587.txt', 'receta588.txt', 'receta589.txt', 'receta590.txt', 'receta591.txt', 'receta592.txt', 'receta813.txt', 'receta814.txt', 'receta815.txt', 'receta816.txt', 'receta817.txt', 'receta818.txt', 'receta819.txt', 'receta820.txt', 'receta941.txt', 'receta942.txt', 'receta943.txt', 'receta944.txt', 'receta945.txt', 'receta946.txt', 'receta947.txt', 'receta948.txt', 'receta949.txt', 'receta95.txt', 'receta950.txt', 'receta951.txt', 'receta952.txt', 'receta953.txt', 'receta954.txt', 'receta955.txt', 'receta956.txt', 'receta957.txt', 'receta958.txt', 'receta959.txt', 'receta960.txt', 'receta961.txt', 'receta962.txt', 'receta963.txt', 'receta964.txt', 'receta965.txt', 'receta966.txt', 'receta967.txt', 'receta968.txt', 'receta969.txt', 'receta970.txt', 'receta971.txt', 'receta972.txt', 'receta973.txt', 'receta974.txt', 'receta975.txt', 'receta976.txt', 'receta977.txt', 'receta978.txt', 'receta979.txt', 'receta980.txt', 'receta981.txt', 'receta982.txt', 'receta983.txt', 'receta984.txt', 'receta985.txt', 'receta986.txt', 'receta987.txt', 'receta988.txt', 'receta989.txt', 'receta990.txt']\n",
      "5./Interfaz/recetastextos/Carpeta Pescados/-----------------\n",
      "['receta1000.txt', 'receta1001.txt', 'receta1002.txt', 'receta1003.txt', 'receta1004.txt', 'receta1005.txt', 'receta1006.txt', 'receta1007.txt', 'receta1008.txt', 'receta1009.txt', 'receta1010.txt', 'receta1011.txt', 'receta1012.txt', 'receta1013.txt', 'receta1014.txt', 'receta1015.txt', 'receta1016.txt', 'receta1017.txt', 'receta1018.txt', 'receta1019.txt', 'receta1020.txt', 'receta1021.txt', 'receta1022.txt', 'receta1023.txt', 'receta1024.txt', 'receta1025.txt', 'receta1026.txt', 'receta1027.txt', 'receta1028.txt', 'receta1029.txt', 'receta1030.txt', 'receta1031.txt', 'receta1032.txt', 'receta1033.txt', 'receta1034.txt', 'receta1035.txt', 'receta1036.txt', 'receta1037.txt', 'receta1038.txt', 'receta1039.txt', 'receta1040.txt', 'receta11.txt', 'receta123.txt', 'receta1259.txt', 'receta1260.txt', 'receta1261.txt', 'receta1262.txt', 'receta1263.txt', 'receta1264.txt', 'receta1265.txt', 'receta1266.txt', 'receta1267.txt', 'receta1268.txt', 'receta1269.txt', 'receta1270.txt', 'receta1271.txt', 'receta1272.txt', 'receta1273.txt', 'receta1274.txt', 'receta1275.txt', 'receta1276.txt', 'receta1277.txt', 'receta1278.txt', 'receta1279.txt', 'receta1280.txt', 'receta1281.txt', 'receta1282.txt', 'receta1283.txt', 'receta1284.txt', 'receta1285.txt', 'receta1286.txt', 'receta1287.txt', 'receta1288.txt', 'receta1289.txt', 'receta1290.txt', 'receta1291.txt', 'receta1292.txt', 'receta1293.txt', 'receta1294.txt', 'receta1295.txt', 'receta1296.txt', 'receta1297.txt', 'receta1298.txt', 'receta1299.txt', 'receta1300.txt', 'receta1301.txt', 'receta1302.txt', 'receta1303.txt', 'receta1304.txt', 'receta1305.txt', 'receta1306.txt', 'receta1307.txt', 'receta1308.txt', 'receta1309.txt', 'receta1310.txt', 'receta1311.txt', 'receta181.txt', 'receta190.txt', 'receta194.txt', 'receta1992.txt', 'receta1993.txt', 'receta1994.txt', 'receta1995.txt', 'receta1996.txt', 'receta1997.txt', 'receta1998.txt', 'receta1999.txt', 'receta2000.txt', 'receta2001.txt', 'receta2002.txt', 'receta2003.txt', 'receta2004.txt', 'receta2005.txt', 'receta2006.txt', 'receta2007.txt', 'receta2008.txt', 'receta2009.txt', 'receta2010.txt', 'receta2011.txt', 'receta2012.txt', 'receta2013.txt', 'receta2014.txt', 'receta2015.txt', 'receta2016.txt', 'receta2017.txt', 'receta2018.txt', 'receta2019.txt', 'receta2020.txt', 'receta2021.txt', 'receta2022.txt', 'receta2023.txt', 'receta2024.txt', 'receta2025.txt', 'receta2026.txt', 'receta2027.txt', 'receta2028.txt', 'receta2029.txt', 'receta2030.txt', 'receta2031.txt', 'receta2032.txt', 'receta2033.txt', 'receta2034.txt', 'receta2035.txt', 'receta2036.txt', 'receta2037.txt', 'receta2038.txt', 'receta2039.txt', 'receta2040.txt', 'receta2041.txt', 'receta2042.txt', 'receta2043.txt', 'receta2044.txt', 'receta2045.txt', 'receta2046.txt', 'receta2047.txt', 'receta2048.txt', 'receta2049.txt', 'receta2050.txt', 'receta2051.txt', 'receta2052.txt', 'receta2053.txt', 'receta2054.txt', 'receta2055.txt', 'receta2056.txt', 'receta2057.txt', 'receta2058.txt', 'receta2059.txt', 'receta2060.txt', 'receta2061.txt', 'receta2062.txt', 'receta2063.txt', 'receta2064.txt', 'receta2065.txt', 'receta2066.txt', 'receta2067.txt', 'receta2068.txt', 'receta2069.txt', 'receta2070.txt', 'receta2071.txt', 'receta2072.txt', 'receta2073.txt', 'receta2074.txt', 'receta2075.txt', 'receta2076.txt', 'receta2077.txt', 'receta2078.txt', 'receta2079.txt', 'receta2080.txt', 'receta25.txt', 'receta297.txt', 'receta299.txt', 'receta301.txt', 'receta304.txt', 'receta323.txt', 'receta325.txt', 'receta332.txt', 'receta335.txt', 'receta336.txt', 'receta337.txt', 'receta338.txt', 'receta340.txt', 'receta480.txt', 'receta482.txt', 'receta484.txt', 'receta485.txt', 'receta488.txt', 'receta489.txt', 'receta490.txt', 'receta492.txt', 'receta493.txt', 'receta494.txt', 'receta495.txt', 'receta496.txt', 'receta497.txt', 'receta499.txt', 'receta500.txt', 'receta503.txt', 'receta504.txt', 'receta507.txt', 'receta508.txt', 'receta509.txt', 'receta513.txt', 'receta514.txt', 'receta519.txt', 'receta527.txt', 'receta530.txt', 'receta531.txt', 'receta537.txt', 'receta539.txt', 'receta596.txt', 'receta598.txt', 'receta601.txt', 'receta609.txt', 'receta611.txt', 'receta614.txt', 'receta617.txt', 'receta619.txt', 'receta620.txt', 'receta621.txt', 'receta622.txt', 'receta624.txt', 'receta625.txt', 'receta627.txt', 'receta629.txt', 'receta630.txt', 'receta7.txt', 'receta74.txt', 'receta81.txt', 'receta88.txt', 'receta991.txt', 'receta992.txt', 'receta993.txt', 'receta994.txt', 'receta995.txt', 'receta996.txt', 'receta997.txt', 'receta998.txt', 'receta999.txt']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6./Interfaz/recetastextos/Carpeta Platos Menores/-----------------\n",
      "['receta112.txt', 'receta1332.txt', 'receta1333.txt', 'receta1334.txt', 'receta1335.txt', 'receta1336.txt', 'receta1337.txt', 'receta1338.txt', 'receta1339.txt', 'receta1340.txt', 'receta1341.txt', 'receta1342.txt', 'receta1343.txt', 'receta1344.txt', 'receta1345.txt', 'receta1346.txt', 'receta1347.txt', 'receta1348.txt', 'receta1349.txt', 'receta1350.txt', 'receta1351.txt', 'receta1352.txt', 'receta1353.txt', 'receta1354.txt', 'receta1355.txt', 'receta1356.txt', 'receta1357.txt', 'receta1358.txt', 'receta1359.txt', 'receta1360.txt', 'receta1361.txt', 'receta1362.txt', 'receta1363.txt', 'receta1364.txt', 'receta1365.txt', 'receta1366.txt', 'receta1367.txt', 'receta1368.txt', 'receta1369.txt', 'receta1370.txt', 'receta1371.txt', 'receta1372.txt', 'receta1373.txt', 'receta1374.txt', 'receta1375.txt', 'receta1376.txt', 'receta1377.txt', 'receta1378.txt', 'receta1379.txt', 'receta1380.txt', 'receta1381.txt', 'receta1382.txt', 'receta1383.txt', 'receta1384.txt', 'receta1385.txt', 'receta1386.txt', 'receta1387.txt', 'receta1388.txt', 'receta1389.txt', 'receta1390.txt', 'receta1391.txt', 'receta1392.txt', 'receta1393.txt', 'receta1394.txt', 'receta1395.txt', 'receta1396.txt', 'receta1397.txt', 'receta1398.txt', 'receta1399.txt', 'receta14.txt', 'receta1400.txt', 'receta1401.txt', 'receta1402.txt', 'receta1403.txt', 'receta1404.txt', 'receta1405.txt', 'receta1406.txt', 'receta1407.txt', 'receta1408.txt', 'receta1409.txt', 'receta1410.txt', 'receta1411.txt', 'receta1412.txt', 'receta1413.txt', 'receta1414.txt', 'receta1415.txt', 'receta1416.txt', 'receta1417.txt', 'receta1418.txt', 'receta1419.txt', 'receta1420.txt', 'receta1421.txt', 'receta1422.txt', 'receta1423.txt', 'receta1424.txt', 'receta1425.txt', 'receta1426.txt', 'receta1427.txt', 'receta1428.txt', 'receta1429.txt', 'receta1430.txt', 'receta1431.txt', 'receta1432.txt', 'receta1433.txt', 'receta1434.txt', 'receta1435.txt', 'receta1436.txt', 'receta1437.txt', 'receta1438.txt', 'receta1439.txt', 'receta1440.txt', 'receta1441.txt', 'receta1442.txt', 'receta1443.txt', 'receta1444.txt', 'receta1445.txt', 'receta1446.txt', 'receta1447.txt', 'receta1448.txt', 'receta1449.txt', 'receta1450.txt', 'receta1451.txt', 'receta1452.txt', 'receta1453.txt', 'receta1454.txt', 'receta1455.txt', 'receta1456.txt', 'receta1457.txt', 'receta1458.txt', 'receta1459.txt', 'receta1460.txt', 'receta1461.txt', 'receta1462.txt', 'receta1463.txt', 'receta1464.txt', 'receta1465.txt', 'receta1466.txt', 'receta1467.txt', 'receta1468.txt', 'receta1469.txt', 'receta1470.txt', 'receta1471.txt', 'receta1472.txt', 'receta1473.txt', 'receta1474.txt', 'receta1475.txt', 'receta1476.txt', 'receta1477.txt', 'receta1478.txt', 'receta1479.txt', 'receta1480.txt', 'receta1481.txt', 'receta1482.txt', 'receta1483.txt', 'receta1484.txt', 'receta1485.txt', 'receta1486.txt', 'receta1487.txt', 'receta1488.txt', 'receta1489.txt', 'receta1490.txt', 'receta1491.txt', 'receta18.txt', 'receta1890.txt', 'receta1891.txt', 'receta1892.txt', 'receta1893.txt', 'receta1894.txt', 'receta1895.txt', 'receta1896.txt', 'receta1897.txt', 'receta1898.txt', 'receta1899.txt', 'receta1900.txt', 'receta1901.txt', 'receta1902.txt', 'receta1903.txt', 'receta1904.txt', 'receta1905.txt', 'receta1906.txt', 'receta1907.txt', 'receta1908.txt', 'receta1909.txt', 'receta1910.txt', 'receta1911.txt', 'receta1912.txt', 'receta1913.txt', 'receta1914.txt', 'receta1915.txt', 'receta1916.txt', 'receta1917.txt', 'receta1918.txt', 'receta1919.txt', 'receta1920.txt', 'receta1921.txt', 'receta1922.txt', 'receta1923.txt', 'receta1924.txt', 'receta1925.txt', 'receta1926.txt', 'receta1927.txt', 'receta1928.txt', 'receta1929.txt', 'receta1930.txt', 'receta1931.txt', 'receta1932.txt', 'receta1933.txt', 'receta1934.txt', 'receta1935.txt', 'receta1936.txt', 'receta1937.txt', 'receta1938.txt', 'receta1939.txt', 'receta1940.txt', 'receta1941.txt', 'receta1942.txt', 'receta1943.txt', 'receta1944.txt', 'receta1945.txt', 'receta1946.txt', 'receta1947.txt', 'receta1948.txt', 'receta1949.txt', 'receta1950.txt', 'receta1951.txt', 'receta1952.txt', 'receta1953.txt', 'receta1954.txt', 'receta1955.txt', 'receta1956.txt', 'receta1957.txt', 'receta1958.txt', 'receta1959.txt', 'receta1960.txt', 'receta1961.txt', 'receta1962.txt', 'receta1963.txt', 'receta1964.txt', 'receta1965.txt', 'receta1966.txt', 'receta1967.txt', 'receta1968.txt', 'receta1969.txt', 'receta1970.txt', 'receta1971.txt', 'receta1972.txt', 'receta1973.txt', 'receta1974.txt', 'receta1975.txt', 'receta1976.txt', 'receta1977.txt', 'receta1978.txt', 'receta1979.txt', 'receta1980.txt', 'receta1981.txt', 'receta1982.txt', 'receta1983.txt', 'receta1984.txt', 'receta1985.txt', 'receta1986.txt', 'receta1987.txt', 'receta1988.txt', 'receta1989.txt', 'receta1990.txt', 'receta1991.txt', 'receta2.txt', 'receta227.txt', 'receta27.txt', 'receta30.txt', 'receta38.txt', 'receta4.txt', 'receta47.txt', 'receta50.txt', 'receta53.txt', 'receta57.txt', 'receta60.txt', 'receta61.txt', 'receta69.txt', 'receta704.txt', 'receta705.txt', 'receta706.txt', 'receta711.txt', 'receta714.txt', 'receta716.txt', 'receta718.txt', 'receta72.txt', 'receta720.txt', 'receta721.txt', 'receta736.txt', 'receta737.txt', 'receta738.txt', 'receta739.txt', 'receta740.txt', 'receta741.txt', 'receta742.txt', 'receta743.txt', 'receta745.txt', 'receta746.txt', 'receta747.txt', 'receta748.txt', 'receta749.txt', 'receta75.txt', 'receta750.txt', 'receta751.txt', 'receta752.txt', 'receta754.txt', 'receta755.txt', 'receta757.txt', 'receta759.txt', 'receta760.txt', 'receta762.txt', 'receta763.txt', 'receta764.txt', 'receta765.txt', 'receta766.txt', 'receta767.txt', 'receta768.txt', 'receta769.txt', 'receta770.txt', 'receta771.txt', 'receta772.txt', 'receta773.txt', 'receta774.txt', 'receta775.txt', 'receta776.txt', 'receta777.txt', 'receta778.txt', 'receta779.txt', 'receta78.txt', 'receta780.txt', 'receta821.txt', 'receta822.txt', 'receta823.txt', 'receta824.txt', 'receta825.txt', 'receta826.txt', 'receta827.txt', 'receta828.txt', 'receta829.txt', 'receta830.txt', 'receta831.txt', 'receta832.txt', 'receta833.txt', 'receta834.txt', 'receta835.txt', 'receta836.txt', 'receta837.txt', 'receta838.txt', 'receta839.txt', 'receta840.txt', 'receta841.txt', 'receta842.txt', 'receta843.txt', 'receta844.txt', 'receta845.txt', 'receta846.txt', 'receta847.txt', 'receta848.txt', 'receta849.txt', 'receta850.txt', 'receta851.txt', 'receta852.txt', 'receta853.txt', 'receta854.txt', 'receta855.txt', 'receta856.txt', 'receta857.txt', 'receta858.txt', 'receta859.txt', 'receta860.txt', 'receta861.txt', 'receta862.txt', 'receta863.txt', 'receta864.txt', 'receta865.txt', 'receta866.txt', 'receta867.txt', 'receta868.txt', 'receta869.txt', 'receta87.txt', 'receta870.txt', 'receta9.txt']\n",
      "7./Interfaz/recetastextos/Carpeta Verduras/-----------------\n",
      "['receta1041.txt', 'receta1042.txt', 'receta1043.txt', 'receta1044.txt', 'receta1045.txt', 'receta1046.txt', 'receta1047.txt', 'receta1048.txt', 'receta1049.txt', 'receta1050.txt', 'receta1051.txt', 'receta1052.txt', 'receta1053.txt', 'receta1054.txt', 'receta1055.txt', 'receta1056.txt', 'receta1057.txt', 'receta1058.txt', 'receta1059.txt', 'receta1060.txt', 'receta1061.txt', 'receta1062.txt', 'receta1063.txt', 'receta1064.txt', 'receta1065.txt', 'receta1066.txt', 'receta1067.txt', 'receta1068.txt', 'receta1069.txt', 'receta1070.txt', 'receta1071.txt', 'receta1072.txt', 'receta1073.txt', 'receta1074.txt', 'receta1075.txt', 'receta1076.txt', 'receta1077.txt', 'receta1078.txt', 'receta1079.txt', 'receta1080.txt', 'receta1081.txt', 'receta1082.txt', 'receta1083.txt', 'receta1084.txt', 'receta1085.txt', 'receta1086.txt', 'receta1087.txt', 'receta1088.txt', 'receta1089.txt', 'receta1090.txt', 'receta1091.txt', 'receta1092.txt', 'receta1093.txt', 'receta1094.txt', 'receta1095.txt', 'receta1096.txt', 'receta1097.txt', 'receta1098.txt', 'receta1099.txt', 'receta1100.txt', 'receta1101.txt', 'receta1102.txt', 'receta1103.txt', 'receta1104.txt', 'receta1105.txt', 'receta1106.txt', 'receta1107.txt', 'receta1108.txt', 'receta1109.txt', 'receta1110.txt', 'receta1111.txt', 'receta1112.txt', 'receta1113.txt', 'receta1114.txt', 'receta1115.txt', 'receta1116.txt', 'receta1117.txt', 'receta1118.txt', 'receta1119.txt', 'receta1120.txt', 'receta1121.txt', 'receta1122.txt', 'receta1123.txt', 'receta1124.txt', 'receta1125.txt', 'receta1126.txt', 'receta1127.txt', 'receta1128.txt', 'receta1129.txt', 'receta1130.txt', 'receta1131.txt', 'receta1132.txt', 'receta1133.txt', 'receta1134.txt', 'receta1135.txt', 'receta1136.txt', 'receta119.txt', 'receta13.txt', 'receta1492.txt', 'receta1493.txt', 'receta1494.txt', 'receta1495.txt', 'receta1496.txt', 'receta1497.txt', 'receta1498.txt', 'receta1499.txt', 'receta1500.txt', 'receta1501.txt', 'receta1502.txt', 'receta1503.txt', 'receta1504.txt', 'receta1505.txt', 'receta1506.txt', 'receta1507.txt', 'receta1508.txt', 'receta1509.txt', 'receta1510.txt', 'receta1511.txt', 'receta1512.txt', 'receta1513.txt', 'receta1514.txt', 'receta1515.txt', 'receta1516.txt', 'receta1517.txt', 'receta1518.txt', 'receta1519.txt', 'receta1520.txt', 'receta1521.txt', 'receta1522.txt', 'receta1523.txt', 'receta1524.txt', 'receta1525.txt', 'receta1526.txt', 'receta1527.txt', 'receta1528.txt', 'receta1529.txt', 'receta1530.txt', 'receta1531.txt', 'receta1532.txt', 'receta1533.txt', 'receta1534.txt', 'receta1535.txt', 'receta1536.txt', 'receta1537.txt', 'receta1538.txt', 'receta1539.txt', 'receta1540.txt', 'receta1541.txt', 'receta1542.txt', 'receta1543.txt', 'receta1544.txt', 'receta1545.txt', 'receta1546.txt', 'receta1547.txt', 'receta1548.txt', 'receta17.txt', 'receta2143.txt', 'receta2144.txt', 'receta2145.txt', 'receta2146.txt', 'receta2147.txt', 'receta2148.txt', 'receta2149.txt', 'receta2150.txt', 'receta2151.txt', 'receta2152.txt', 'receta2153.txt', 'receta2154.txt', 'receta2155.txt', 'receta2156.txt', 'receta2157.txt', 'receta2158.txt', 'receta2159.txt', 'receta2160.txt', 'receta2161.txt', 'receta2162.txt', 'receta2163.txt', 'receta2164.txt', 'receta2165.txt', 'receta2166.txt', 'receta2167.txt', 'receta2168.txt', 'receta2169.txt', 'receta2170.txt', 'receta2171.txt', 'receta2172.txt', 'receta2173.txt', 'receta2174.txt', 'receta2175.txt', 'receta2176.txt', 'receta2177.txt', 'receta2178.txt', 'receta2179.txt', 'receta2180.txt', 'receta2181.txt', 'receta2182.txt', 'receta2183.txt', 'receta2184.txt', 'receta2185.txt', 'receta2186.txt', 'receta2187.txt', 'receta2188.txt', 'receta2189.txt', 'receta2190.txt', 'receta2191.txt', 'receta2192.txt', 'receta2193.txt', 'receta2194.txt', 'receta2195.txt', 'receta2196.txt', 'receta2197.txt', 'receta2198.txt', 'receta2199.txt', 'receta2200.txt', 'receta2201.txt', 'receta2202.txt', 'receta2203.txt', 'receta2204.txt', 'receta2205.txt', 'receta2206.txt', 'receta2207.txt', 'receta2208.txt', 'receta2209.txt', 'receta2210.txt', 'receta2211.txt', 'receta2212.txt', 'receta2213.txt', 'receta2214.txt', 'receta2215.txt', 'receta2216.txt', 'receta2217.txt', 'receta2218.txt', 'receta2219.txt', 'receta2220.txt', 'receta2221.txt', 'receta2222.txt', 'receta2223.txt', 'receta2224.txt', 'receta2225.txt', 'receta2226.txt', 'receta2227.txt', 'receta2228.txt', 'receta2229.txt', 'receta2230.txt', 'receta2231.txt', 'receta2232.txt', 'receta2233.txt', 'receta2234.txt', 'receta2235.txt', 'receta2236.txt', 'receta2237.txt', 'receta2238.txt', 'receta2239.txt', 'receta2240.txt', 'receta2241.txt', 'receta2242.txt', 'receta2243.txt', 'receta2244.txt', 'receta2245.txt', 'receta2246.txt', 'receta2247.txt', 'receta2248.txt', 'receta2249.txt', 'receta2250.txt', 'receta2251.txt', 'receta2252.txt', 'receta2253.txt', 'receta2254.txt', 'receta2255.txt', 'receta2256.txt', 'receta2257.txt', 'receta2258.txt', 'receta2259.txt', 'receta2260.txt', 'receta2261.txt', 'receta2262.txt', 'receta2263.txt', 'receta2264.txt', 'receta2265.txt', 'receta2266.txt', 'receta2267.txt', 'receta296.txt', 'receta339.txt', 'receta342.txt', 'receta343.txt', 'receta346.txt', 'receta347.txt', 'receta348.txt', 'receta349.txt', 'receta350.txt', 'receta352.txt', 'receta353.txt', 'receta354.txt', 'receta355.txt', 'receta356.txt', 'receta357.txt', 'receta36.txt', 'receta431.txt', 'receta433.txt', 'receta434.txt', 'receta435.txt', 'receta436.txt', 'receta438.txt', 'receta439.txt', 'receta440.txt', 'receta442.txt', 'receta446.txt', 'receta447.txt', 'receta448.txt', 'receta451.txt', 'receta454.txt', 'receta455.txt', 'receta456.txt', 'receta457.txt', 'receta459.txt', 'receta460.txt', 'receta462.txt', 'receta608.txt', 'receta64.txt', 'receta723.txt', 'receta724.txt', 'receta725.txt', 'receta726.txt', 'receta729.txt', 'receta730.txt', 'receta731.txt', 'receta732.txt', 'receta733.txt', 'receta734.txt', 'receta92.txt', 'receta94.txt']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nprint(len(listaTextosCarpeta))\\n#for l in listaTextosCarpeta:\\n#    print('----------------------------------------------------------------------------')\\n#    print(l)\\n#    print('----------------------------------------------------------------------------')\\n#    print('----------------------------------------------------------------------------')\\n\\n\\nstemsArroz=p.tratamientoTextos(listaTextosCarpeta[0])\\nprint(stemsArroz)\\nstemsBebidas=p.tratamientoTextos(listaTextosCarpeta[1])\\nprint(stemsBebidas)\\nstemsCarne=p.tratamientoTextos(listaTextosCarpeta[2])\\nprint(stemsCarne)\\nstemsMarisco=p.tratamientoTextos(listaTextosCarpeta[3])\\nprint(stemsMarisco)\\nstemsPasta=p.tratamientoTextos(listaTextosCarpeta[4])\\nprint(stemsPasta)\\nstemsPescados=p.tratamientoTextos(listaTextosCarpeta[5])\\nprint(stemsPescados)\\nstemsPlatosMenores=p.tratamientoTextos(listaTextosCarpeta[6])\\nprint(stemsPlatosMenores)\\nstemsVerduras=p.tratamientoTextos(listaTextosCarpeta[7])\\nprint(stemsVerduras)\\n\\nprint('----------------------------')\\n\\nlistaTextosTesting=p.lecturaTesting()\\nprint(listaTextosTesting)\\nstemsTesting=p.tratamientoTextos(listaTextosTesting)\\nprint(stemsTesting)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ProcesarDocumentos:     \n",
    "    def lectura(self):\n",
    "        procDoc=ProcesarDocumentos()\n",
    "        rutaCarpetasPorCategoria = \"./Interfaz/recetastextos/\"\n",
    "        listaCarpetasFinal = []\n",
    "        #estos string nos servir√°n para guardar todos los textos de los txt por cada una de las carpetas\n",
    "        carpetaArroz = carpetaBebidas = carpetaCarnes = carpetaMarisco = carpetaPasta = carpetaPescados = carpetaPlatosMenores = carpetaVerduras = ''\n",
    "        #sacamos una lista de todas las carpetas\n",
    "        listaCarpetas = os.listdir(rutaCarpetasPorCategoria)\n",
    "        #print(listaCarpetas)\n",
    "        #print(len(listaCarpetas))\n",
    "        #recorremos todas las carpetas\n",
    "        i=0\n",
    "        for lc in listaCarpetas:\n",
    "            #cogemos el nombre de la carpeta y se lo concatenamos a la ruta anterior\n",
    "            rutaPorCarpeta = rutaCarpetasPorCategoria + lc + '/'\n",
    "            print(str(i)+rutaPorCarpeta+'-----------------')\n",
    "            if(i==0):\n",
    "                carpetaArroz = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                #print(carpetaArroz)\n",
    "                listaCarpetasFinal.append(carpetaArroz)\n",
    "            if(i==1):\n",
    "                carpetaBebidas = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaBebidas)\n",
    "            if(i==2):\n",
    "                carpetaCarnes = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaCarnes)\n",
    "            if(i==3):\n",
    "                carpetaMarisco = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaMarisco)\n",
    "            if(i==4):\n",
    "                carpetaPasta = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaPasta)\n",
    "            if(i==5):\n",
    "                carpetaPescados = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaPescados)\n",
    "            if(i==6):\n",
    "                carpetaPlatosMenores = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaPlatosMenores)\n",
    "            if(i==7):\n",
    "                carpetaVerduras = procDoc.resultadoStringCarpeta(rutaPorCarpeta)\n",
    "                listaCarpetasFinal.append(carpetaVerduras)\n",
    "            i=i+1\n",
    "        return listaCarpetasFinal\n",
    "    def lecturaTesting(self):\n",
    "        procDoc=ProcesarDocumentos()\n",
    "        rutaCarpetaTesting = \"./Interfaz/Carpeta Testing/\"\n",
    "        carpetaTesting = procDoc.resultadoStringCarpeta(rutaCarpetaTesting)\n",
    "        return carpetaTesting\n",
    "    def resultadoStringCarpeta(self, rutaPorCarpeta):\n",
    "        strCarpeta=[]\n",
    "        #vemos el contenido de la carpeta en la que estamos iterando\n",
    "        listaTxt = os.listdir(rutaPorCarpeta)\n",
    "        print(listaTxt)\n",
    "        #recorremos todos los archivos de la carpeta\n",
    "        for lt in listaTxt:\n",
    "            #concatenamos la ruta de la carpeta con el nombre de los archivos que contiene esta\n",
    "            rutaTxt = rutaPorCarpeta + lt\n",
    "            #al ir iterando pasaremos por todos los archivos modificando la variable de la ruta para poder hacer un open con ella\n",
    "            #file = open(filename, encoding=\"utf8\")\n",
    "            try:\n",
    "                with open(rutaTxt, 'r') as f: \n",
    "                    #al hacer el open leemos lo que hay dentro del archivo con f.read(), y esto lo guardamos dentro de un string inicializado al inicio del todo\n",
    "                    strCarpeta.append(f.read())\n",
    "            except:\n",
    "                with open(rutaTxt, 'r',encoding=\"utf8\") as f: \n",
    "                    #al hacer el open leemos lo que hay dentro del archivo con f.read(), y esto lo guardamos dentro de un string inicializado al inicio del todo\n",
    "                    strCarpeta.append(f.read())\n",
    "                \n",
    "        return strCarpeta\n",
    "    def leer_stopwords(self, path):\n",
    "        with open(path) as f:\n",
    "            # Lee las stopwords del archivo y las guarda en una lista\n",
    "            mis_stopwords = [line.strip() for line in f]\n",
    "        return mis_stopwords\n",
    "    def tratamientoTextos(self, info):\n",
    "        #Eliminamos posibles horas del titulo\n",
    "        textoSinSimbolos = re.sub(\"\\d+:\\d+:\\d+\", \"\" , info)\n",
    "        #Eliminamos posibles fechas\n",
    "        textoSinSimbolos = re.sub(\"\\d+-\\d+-\\d+\", \"\" , textoSinSimbolos)\n",
    "        #Eliminamos todos los fin de enlace\n",
    "        textoSinSimbolos = re.sub(\"v=.*\", \"\" , textoSinSimbolos)\n",
    "        #Eliminamos todos los simbolos del texto (,.;:?¬ø!!) etc\n",
    "        textoSinSimbolos = re.sub(\"[^0-9A-Za-z_]\", \" \" , textoSinSimbolos)\n",
    "        #Sacamos todos los tokens del texto y los metemos en una lista\n",
    "        textoTokenizado = nltk.tokenize.word_tokenize(textoSinSimbolos)\n",
    "        #una lista no tiene lower asique pasamos el lower con map a toda la lista\n",
    "        textoMinusculas = (map(lambda x: x.lower(), textoTokenizado))\n",
    "        #Le pasa un stopword de palabras en espa√±ol a la lista de palabras que le llega\n",
    "        #stop_words_sp = set(stopwords.words('spanish'))\n",
    "        stop_words_sp = self.leer_stopwords(\"./Interfaz/rapidminer/stop_words_spanish.txt\")\n",
    "        pasarStopWords = [i for i in textoMinusculas if i not in stop_words_sp]\n",
    "        #Aplicamos la normalizacion mediante stemming\n",
    "        #SnowStem = nltk.SnowballStemmer(language = 'spanish')\n",
    "        # Crear un objeto SnowballStemmer para el idioma espa√±ol\n",
    "        stemmer = RSLPStemmer()\n",
    "        listaStems = [stemmer.stem(word) for word in pasarStopWords]\n",
    "        return listaStems\n",
    "\n",
    "\n",
    "p=ProcesarDocumentos()\n",
    "listaTextosCarpeta=p.lectura()\n",
    "\"\"\"\n",
    "print(len(listaTextosCarpeta))\n",
    "#for l in listaTextosCarpeta:\n",
    "#    print('----------------------------------------------------------------------------')\n",
    "#    print(l)\n",
    "#    print('----------------------------------------------------------------------------')\n",
    "#    print('----------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "stemsArroz=p.tratamientoTextos(listaTextosCarpeta[0])\n",
    "print(stemsArroz)\n",
    "stemsBebidas=p.tratamientoTextos(listaTextosCarpeta[1])\n",
    "print(stemsBebidas)\n",
    "stemsCarne=p.tratamientoTextos(listaTextosCarpeta[2])\n",
    "print(stemsCarne)\n",
    "stemsMarisco=p.tratamientoTextos(listaTextosCarpeta[3])\n",
    "print(stemsMarisco)\n",
    "stemsPasta=p.tratamientoTextos(listaTextosCarpeta[4])\n",
    "print(stemsPasta)\n",
    "stemsPescados=p.tratamientoTextos(listaTextosCarpeta[5])\n",
    "print(stemsPescados)\n",
    "stemsPlatosMenores=p.tratamientoTextos(listaTextosCarpeta[6])\n",
    "print(stemsPlatosMenores)\n",
    "stemsVerduras=p.tratamientoTextos(listaTextosCarpeta[7])\n",
    "print(stemsVerduras)\n",
    "\n",
    "print('----------------------------')\n",
    "\n",
    "listaTextosTesting=p.lecturaTesting()\n",
    "print(listaTextosTesting)\n",
    "stemsTesting=p.tratamientoTextos(listaTextosTesting)\n",
    "print(stemsTesting)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dec6bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listaTextosCarpeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28fe8aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responde con 1 cuando quieras incluir la categor√≠a y 0 cuando no\n",
      "Quieres meter arroces?1\n",
      "Quieres meter bebidas?1\n",
      "Quieres meter carnes?1\n",
      "Quieres meter marisco?1\n",
      "Quieres meter pasta?1\n",
      "Quieres meter pescados?1\n",
      "Quieres meter platos menores?1\n",
      "Quieres meter verduras?1\n",
      "['1', '1', '1', '1', '1', '1', '1', '1']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>receta</th>\n",
       "      <th>clasif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ensal, arroz, mediterr, nea, veran, cociner, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[haz, arroz, band, 10, recet, pas, pas, mir, m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[arroz, mel, sep, gamb, alcachof, recet, cocin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[arroz, manit, cerd, set, recet, cocin, famil,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[paell, bacala, costr, aliol, recet, cocin, fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>[calabac, n, m, s, delici, com, recet, calabac...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>[fr, cali, tu, decid, com, delic, repoll, rece...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>[sop, past, alem, past, elab, 1, minut, d, as,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>[recet, crem, calabaz, companion, jord, cruz, ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>[patat, mediterrane, andaluc, videorecet, entr...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1861 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 receta clasif\n",
       "0     [ensal, arroz, mediterr, nea, veran, cociner, ...      0\n",
       "1     [haz, arroz, band, 10, recet, pas, pas, mir, m...      0\n",
       "2     [arroz, mel, sep, gamb, alcachof, recet, cocin...      0\n",
       "3     [arroz, manit, cerd, set, recet, cocin, famil,...      0\n",
       "4     [paell, bacala, costr, aliol, recet, cocin, fa...      0\n",
       "...                                                 ...    ...\n",
       "1856  [calabac, n, m, s, delici, com, recet, calabac...      7\n",
       "1857  [fr, cali, tu, decid, com, delic, repoll, rece...      7\n",
       "1858  [sop, past, alem, past, elab, 1, minut, d, as,...      7\n",
       "1859  [recet, crem, calabaz, companion, jord, cruz, ...      7\n",
       "1860  [patat, mediterrane, andaluc, videorecet, entr...      7\n",
       "\n",
       "[1861 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['receta']=None\n",
    "df['clasif']=None\n",
    "print(\"Responde con 1 cuando quieras incluir la categor√≠a y 0 cuando no\")\n",
    "\n",
    "sel=[]\n",
    "\n",
    "arroz=input(\"Quieres meter arroces?\")\n",
    "sel.append(arroz)\n",
    "bebida=input(\"Quieres meter bebidas?\")\n",
    "sel.append(bebida)\n",
    "carne=input(\"Quieres meter carnes?\")\n",
    "sel.append(carne)\n",
    "marisco=input(\"Quieres meter marisco?\")\n",
    "sel.append(marisco)\n",
    "pasta=input(\"Quieres meter pasta?\")\n",
    "sel.append(pasta)\n",
    "pescado=input(\"Quieres meter pescados?\")\n",
    "sel.append(pescado)\n",
    "plt_men=input(\"Quieres meter platos menores?\")\n",
    "sel.append(plt_men)\n",
    "verdura=input(\"Quieres meter verduras?\")\n",
    "sel.append(verdura)\n",
    "\n",
    "print(sel)\n",
    "\n",
    "\n",
    "for index,content in enumerate(listaTextosCarpeta):\n",
    "    if sel[index]=='1':\n",
    "        for i in range(len(content)):\n",
    "            text=p.tratamientoTextos(listaTextosCarpeta[index][i])\n",
    "            df=df.append({'receta':text,'clasif':index},ignore_index=True)\n",
    "\n",
    "df\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03d5e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario={0:\"Arroz\",1:\"Bebida\" , \"hola\":\"Carne\" , 3:\"Marisco\",4:\"Pasta\",5:\"Pescado\",6:\"Platos menores\",7:\"Verdura\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19787f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=[3,4,12,6,7,8]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "595e2c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "6\n",
      "7\n",
      "8\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "for i in range(13):\n",
    "    if i in pred:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13ae7e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0./Interfaz/recetastextos/Carpeta Arroz/-----------------\n",
      "['receta108.txt', 'receta12.txt', 'receta125.txt', 'receta133.txt', 'receta134.txt', 'receta139.txt', 'receta1549.txt', 'receta1550.txt', 'receta1561.txt', 'receta1583.txt', 'receta1584.txt', 'receta1586.txt', 'receta1593.txt', 'receta1596.txt', 'receta160.txt', 'receta1610.txt', 'receta1611.txt', 'receta1618.txt', 'receta1620.txt', 'receta1621.txt', 'receta1629.txt', 'receta163.txt', 'receta1635.txt', 'receta165.txt', 'receta1654.txt', 'receta1655.txt', 'receta1656.txt', 'receta1657.txt', 'receta1658.txt', 'receta1666.txt', 'receta1667.txt', 'receta1668.txt', 'receta1669.txt', 'receta1670.txt', 'receta1671.txt', 'receta171.txt', 'receta172.txt', 'receta173.txt', 'receta174.txt', 'receta175.txt', 'receta177.txt', 'receta200.txt', 'receta358.txt', 'receta359.txt', 'receta360.txt', 'receta363.txt', 'receta364.txt', 'receta365.txt', 'receta366.txt', 'receta367.txt', 'receta368.txt', 'receta374.txt', 'receta376.txt', 'receta379.txt', 'receta386.txt', 'receta388.txt', 'receta389.txt', 'receta390.txt', 'receta391.txt', 'receta392.txt', 'receta393.txt', 'receta394.txt', 'receta395.txt', 'receta396.txt', 'receta397.txt', 'receta398.txt', 'receta400.txt', 'receta401.txt', 'receta402.txt', 'receta405.txt', 'receta406.txt', 'receta407.txt', 'receta410.txt', 'receta411.txt', 'receta412.txt', 'receta416.txt', 'receta417.txt', 'receta422.txt', 'receta429.txt', 'receta84.txt', 'receta90.txt']\n",
      "1./Interfaz/recetastextos/Carpeta Bebidas/-----------------\n",
      "['receta1674.txt', 'receta1675.txt', 'receta1676.txt', 'receta1677.txt', 'receta1678.txt', 'receta1679.txt', 'receta1680.txt', 'receta1681.txt', 'receta1682.txt', 'receta1683.txt', 'receta1684.txt', 'receta1685.txt', 'receta1686.txt', 'receta1687.txt', 'receta1688.txt', 'receta1689.txt', 'receta1690.txt', 'receta1691.txt', 'receta1692.txt', 'receta1693.txt', 'receta1694.txt', 'receta1695.txt', 'receta1696.txt', 'receta1697.txt', 'receta1698.txt', 'receta1699.txt', 'receta1700.txt', 'receta1701.txt', 'receta1702.txt', 'receta1703.txt', 'receta1704.txt', 'receta1705.txt', 'receta1706.txt', 'receta1707.txt', 'receta1708.txt', 'receta1709.txt', 'receta1710.txt', 'receta1711.txt', 'receta1712.txt', 'receta1713.txt', 'receta1714.txt', 'receta1715.txt', 'receta1716.txt', 'receta1717.txt', 'receta1718.txt', 'receta1719.txt', 'receta1720.txt', 'receta1721.txt', 'receta1722.txt', 'receta1723.txt', 'receta1724.txt', 'receta1725.txt', 'receta1726.txt', 'receta1727.txt', 'receta1728.txt', 'receta1729.txt', 'receta1730.txt', 'receta1731.txt', 'receta1732.txt', 'receta1733.txt', 'receta623.txt', 'receta633.txt', 'receta634.txt', 'receta635.txt', 'receta636.txt', 'receta637.txt', 'receta638.txt', 'receta639.txt', 'receta640.txt', 'receta641.txt', 'receta642.txt', 'receta643.txt', 'receta644.txt', 'receta645.txt', 'receta646.txt', 'receta648.txt', 'receta649.txt', 'receta651.txt', 'receta652.txt', 'receta653.txt', 'receta654.txt', 'receta655.txt', 'receta656.txt', 'receta657.txt', 'receta658.txt', 'receta659.txt', 'receta660.txt', 'receta661.txt', 'receta662.txt', 'receta663.txt', 'receta664.txt', 'receta665.txt', 'receta666.txt', 'receta668.txt', 'receta669.txt', 'receta670.txt', 'receta671.txt', 'receta672.txt', 'receta674.txt', 'receta675.txt', 'receta676.txt', 'receta678.txt', 'receta679.txt', 'receta680.txt', 'receta681.txt', 'receta682.txt', 'receta683.txt', 'receta685.txt', 'receta686.txt', 'receta687.txt', 'receta688.txt', 'receta690.txt', 'receta692.txt', 'receta693.txt', 'receta694.txt', 'receta695.txt', 'receta696.txt', 'receta698.txt', 'receta700.txt', 'receta701.txt', 'receta702.txt', 'receta703.txt']\n",
      "2./Interfaz/recetastextos/Carpeta Carnes/-----------------\n",
      "['receta1.txt', 'receta1137.txt', 'receta1138.txt', 'receta1139.txt', 'receta114.txt', 'receta1140.txt', 'receta1141.txt', 'receta1142.txt', 'receta1143.txt', 'receta1144.txt', 'receta1145.txt', 'receta1146.txt', 'receta1147.txt', 'receta1148.txt', 'receta1149.txt', 'receta1150.txt', 'receta1151.txt', 'receta1152.txt', 'receta1153.txt', 'receta1154.txt', 'receta1155.txt', 'receta1156.txt', 'receta1157.txt', 'receta1158.txt', 'receta1159.txt', 'receta1160.txt', 'receta1161.txt', 'receta1162.txt', 'receta1163.txt', 'receta1164.txt', 'receta1165.txt', 'receta1166.txt', 'receta1167.txt', 'receta1168.txt', 'receta1169.txt', 'receta1170.txt', 'receta1171.txt', 'receta1172.txt', 'receta1173.txt', 'receta1174.txt', 'receta1175.txt', 'receta1176.txt', 'receta1177.txt', 'receta1178.txt', 'receta1179.txt', 'receta1180.txt', 'receta1181.txt', 'receta1182.txt', 'receta1183.txt', 'receta1184.txt', 'receta1185.txt', 'receta1186.txt', 'receta1187.txt', 'receta1188.txt', 'receta1189.txt', 'receta1190.txt', 'receta1191.txt', 'receta1192.txt', 'receta1193.txt', 'receta1194.txt', 'receta1195.txt', 'receta1196.txt', 'receta1197.txt', 'receta1198.txt', 'receta1199.txt', 'receta16.txt', 'receta1734.txt', 'receta1735.txt', 'receta1736.txt', 'receta1737.txt', 'receta1738.txt', 'receta1739.txt', 'receta1740.txt', 'receta1741.txt', 'receta1742.txt', 'receta1743.txt', 'receta1744.txt', 'receta1745.txt', 'receta1746.txt', 'receta1747.txt', 'receta1748.txt', 'receta1749.txt', 'receta1750.txt', 'receta1751.txt', 'receta1752.txt', 'receta1753.txt', 'receta1754.txt', 'receta1755.txt', 'receta1756.txt', 'receta1757.txt', 'receta1758.txt', 'receta1759.txt', 'receta1760.txt', 'receta1761.txt', 'receta1762.txt', 'receta1763.txt', 'receta1764.txt', 'receta1765.txt', 'receta1766.txt', 'receta1767.txt', 'receta1768.txt', 'receta1769.txt', 'receta1770.txt', 'receta1771.txt', 'receta1772.txt', 'receta1773.txt', 'receta1774.txt', 'receta1775.txt', 'receta1776.txt', 'receta1777.txt', 'receta1778.txt', 'receta1779.txt', 'receta1780.txt', 'receta1781.txt', 'receta1782.txt', 'receta1783.txt', 'receta1784.txt', 'receta1785.txt', 'receta1786.txt', 'receta1787.txt', 'receta1788.txt', 'receta1789.txt', 'receta1790.txt', 'receta1791.txt', 'receta1792.txt', 'receta1793.txt', 'receta1794.txt', 'receta1795.txt', 'receta1796.txt', 'receta1797.txt', 'receta1798.txt', 'receta1799.txt', 'receta1800.txt', 'receta1801.txt', 'receta1802.txt', 'receta1803.txt', 'receta1804.txt', 'receta1805.txt', 'receta1806.txt', 'receta1807.txt', 'receta1808.txt', 'receta1809.txt', 'receta1810.txt', 'receta1811.txt', 'receta1812.txt', 'receta1813.txt', 'receta1814.txt', 'receta1815.txt', 'receta1816.txt', 'receta1817.txt', 'receta1818.txt', 'receta1819.txt', 'receta1820.txt', 'receta1821.txt', 'receta1822.txt', 'receta1823.txt', 'receta1824.txt', 'receta1825.txt', 'receta1826.txt', 'receta1827.txt', 'receta1828.txt', 'receta1829.txt', 'receta1830.txt', 'receta1831.txt', 'receta1832.txt', 'receta1833.txt', 'receta1834.txt', 'receta1835.txt', 'receta1836.txt', 'receta1837.txt', 'receta1838.txt', 'receta1839.txt', 'receta1840.txt', 'receta1841.txt', 'receta1842.txt', 'receta1843.txt', 'receta1844.txt', 'receta1845.txt', 'receta1846.txt', 'receta1847.txt', 'receta1848.txt', 'receta1849.txt', 'receta1850.txt', 'receta1851.txt', 'receta1852.txt', 'receta1853.txt', 'receta1854.txt', 'receta1855.txt', 'receta1856.txt', 'receta1857.txt', 'receta1858.txt', 'receta1859.txt', 'receta1860.txt', 'receta1861.txt', 'receta1862.txt', 'receta1863.txt', 'receta1864.txt', 'receta1865.txt', 'receta1866.txt', 'receta1867.txt', 'receta1868.txt', 'receta1869.txt', 'receta1870.txt', 'receta1871.txt', 'receta1872.txt', 'receta1873.txt', 'receta1874.txt', 'receta1875.txt', 'receta1876.txt', 'receta1877.txt', 'receta1878.txt', 'receta1879.txt', 'receta1880.txt', 'receta1881.txt', 'receta1882.txt', 'receta1883.txt', 'receta1884.txt', 'receta1885.txt', 'receta1886.txt', 'receta1887.txt', 'receta1888.txt', 'receta1889.txt', 'receta209.txt', 'receta258.txt', 'receta259.txt', 'receta260.txt', 'receta261.txt', 'receta262.txt', 'receta263.txt', 'receta264.txt', 'receta266.txt', 'receta267.txt', 'receta268.txt', 'receta269.txt', 'receta270.txt', 'receta271.txt', 'receta272.txt', 'receta273.txt', 'receta274.txt', 'receta275.txt', 'receta276.txt', 'receta277.txt', 'receta278.txt', 'receta280.txt', 'receta281.txt', 'receta282.txt', 'receta283.txt', 'receta284.txt', 'receta285.txt', 'receta286.txt', 'receta287.txt', 'receta29.txt', 'receta3.txt', 'receta31.txt', 'receta32.txt', 'receta39.txt', 'receta42.txt', 'receta43.txt', 'receta48.txt', 'receta51.txt', 'receta58.txt', 'receta6.txt', 'receta63.txt', 'receta65.txt', 'receta71.txt', 'receta73.txt', 'receta77.txt', 'receta781.txt', 'receta782.txt', 'receta783.txt', 'receta784.txt', 'receta785.txt', 'receta786.txt', 'receta787.txt', 'receta788.txt', 'receta789.txt', 'receta790.txt', 'receta791.txt', 'receta792.txt', 'receta793.txt', 'receta794.txt', 'receta795.txt', 'receta796.txt', 'receta797.txt', 'receta798.txt', 'receta799.txt', 'receta8.txt', 'receta800.txt', 'receta801.txt', 'receta802.txt', 'receta803.txt', 'receta804.txt', 'receta805.txt', 'receta806.txt', 'receta807.txt', 'receta808.txt', 'receta809.txt', 'receta810.txt', 'receta811.txt', 'receta812.txt', 'receta83.txt', 'receta871.txt', 'receta872.txt', 'receta873.txt', 'receta874.txt', 'receta875.txt', 'receta876.txt', 'receta877.txt', 'receta878.txt', 'receta879.txt', 'receta880.txt', 'receta881.txt', 'receta882.txt', 'receta883.txt', 'receta884.txt', 'receta885.txt', 'receta886.txt', 'receta887.txt', 'receta888.txt', 'receta889.txt', 'receta890.txt', 'receta891.txt', 'receta892.txt', 'receta893.txt', 'receta894.txt', 'receta895.txt', 'receta896.txt', 'receta897.txt', 'receta898.txt', 'receta899.txt', 'receta900.txt', 'receta901.txt', 'receta902.txt', 'receta903.txt', 'receta904.txt', 'receta905.txt', 'receta906.txt', 'receta907.txt', 'receta908.txt', 'receta909.txt', 'receta910.txt', 'receta911.txt', 'receta912.txt', 'receta913.txt', 'receta914.txt', 'receta915.txt', 'receta916.txt', 'receta917.txt', 'receta918.txt', 'receta919.txt', 'receta920.txt', 'receta93.txt']\n",
      "3./Interfaz/recetastextos/Carpeta Marisco/-----------------\n",
      "['receta180.txt', 'receta184.txt', 'receta185.txt', 'receta195.txt', 'receta202.txt', 'receta203.txt', 'receta204.txt', 'receta205.txt', 'receta212.txt', 'receta213.txt', 'receta214.txt', 'receta216.txt', 'receta218.txt', 'receta219.txt', 'receta221.txt', 'receta224.txt', 'receta226.txt', 'receta26.txt', 'receta298.txt', 'receta306.txt', 'receta310.txt', 'receta319.txt', 'receta322.txt', 'receta330.txt', 'receta333.txt', 'receta334.txt', 'receta35.txt', 'receta41.txt', 'receta481.txt', 'receta486.txt', 'receta487.txt', 'receta491.txt', 'receta5.txt', 'receta501.txt', 'receta502.txt', 'receta505.txt', 'receta510.txt', 'receta515.txt', 'receta516.txt', 'receta517.txt', 'receta518.txt', 'receta520.txt', 'receta521.txt', 'receta522.txt', 'receta524.txt', 'receta525.txt', 'receta528.txt', 'receta532.txt', 'receta540.txt', 'receta541.txt', 'receta542.txt', 'receta544.txt', 'receta552.txt', 'receta602.txt', 'receta632.txt']\n",
      "4./Interfaz/recetastextos/Carpeta Pasta/-----------------\n",
      "['receta118.txt', 'receta120.txt', 'receta1200.txt', 'receta1201.txt', 'receta1202.txt', 'receta1203.txt', 'receta1204.txt', 'receta1205.txt', 'receta1206.txt', 'receta1207.txt', 'receta1208.txt', 'receta1209.txt', 'receta1210.txt', 'receta1211.txt', 'receta1212.txt', 'receta1213.txt', 'receta1214.txt', 'receta1215.txt', 'receta1216.txt', 'receta1217.txt', 'receta1218.txt', 'receta1219.txt', 'receta1220.txt', 'receta1221.txt', 'receta1222.txt', 'receta1223.txt', 'receta1224.txt', 'receta1225.txt', 'receta1226.txt', 'receta1227.txt', 'receta1228.txt', 'receta1229.txt', 'receta1230.txt', 'receta1231.txt', 'receta1232.txt', 'receta1233.txt', 'receta1234.txt', 'receta1235.txt', 'receta1236.txt', 'receta1237.txt', 'receta1238.txt', 'receta1239.txt', 'receta1240.txt', 'receta1241.txt', 'receta1242.txt', 'receta1243.txt', 'receta1244.txt', 'receta1245.txt', 'receta1246.txt', 'receta1247.txt', 'receta1248.txt', 'receta1249.txt', 'receta1250.txt', 'receta1251.txt', 'receta1252.txt', 'receta1253.txt', 'receta1254.txt', 'receta1255.txt', 'receta1256.txt', 'receta1257.txt', 'receta1258.txt', 'receta15.txt', 'receta1551.txt', 'receta1552.txt', 'receta1553.txt', 'receta1554.txt', 'receta1555.txt', 'receta1556.txt', 'receta1557.txt', 'receta1558.txt', 'receta1559.txt', 'receta1560.txt', 'receta1562.txt', 'receta1563.txt', 'receta1564.txt', 'receta1565.txt', 'receta1566.txt', 'receta1567.txt', 'receta1568.txt', 'receta1569.txt', 'receta1570.txt', 'receta1571.txt', 'receta1572.txt', 'receta1573.txt', 'receta1574.txt', 'receta1575.txt', 'receta1576.txt', 'receta1577.txt', 'receta1578.txt', 'receta1579.txt', 'receta1580.txt', 'receta1581.txt', 'receta1582.txt', 'receta1585.txt', 'receta1587.txt', 'receta1588.txt', 'receta1589.txt', 'receta1590.txt', 'receta1591.txt', 'receta1592.txt', 'receta1594.txt', 'receta1595.txt', 'receta1597.txt', 'receta1598.txt', 'receta1599.txt', 'receta1600.txt', 'receta1601.txt', 'receta1602.txt', 'receta1603.txt', 'receta1604.txt', 'receta1605.txt', 'receta1606.txt', 'receta1607.txt', 'receta1608.txt', 'receta1609.txt', 'receta1612.txt', 'receta1613.txt', 'receta1614.txt', 'receta1615.txt', 'receta1616.txt', 'receta1617.txt', 'receta1619.txt', 'receta1622.txt', 'receta1623.txt', 'receta1624.txt', 'receta1625.txt', 'receta1626.txt', 'receta1627.txt', 'receta1628.txt', 'receta1630.txt', 'receta1631.txt', 'receta1632.txt', 'receta1633.txt', 'receta1634.txt', 'receta1636.txt', 'receta1637.txt', 'receta1638.txt', 'receta1639.txt', 'receta1640.txt', 'receta1641.txt', 'receta1642.txt', 'receta1643.txt', 'receta1644.txt', 'receta1645.txt', 'receta1646.txt', 'receta1647.txt', 'receta1648.txt', 'receta1649.txt', 'receta1650.txt', 'receta1651.txt', 'receta1652.txt', 'receta1653.txt', 'receta1659.txt', 'receta1660.txt', 'receta1661.txt', 'receta1662.txt', 'receta1663.txt', 'receta1664.txt', 'receta1665.txt', 'receta1672.txt', 'receta1673.txt', 'receta228.txt', 'receta229.txt', 'receta230.txt', 'receta231.txt', 'receta232.txt', 'receta234.txt', 'receta235.txt', 'receta236.txt', 'receta237.txt', 'receta238.txt', 'receta239.txt', 'receta24.txt', 'receta240.txt', 'receta241.txt', 'receta242.txt', 'receta243.txt', 'receta244.txt', 'receta246.txt', 'receta247.txt', 'receta248.txt', 'receta249.txt', 'receta250.txt', 'receta252.txt', 'receta253.txt', 'receta254.txt', 'receta256.txt', 'receta257.txt', 'receta555.txt', 'receta556.txt', 'receta557.txt', 'receta558.txt', 'receta559.txt', 'receta56.txt', 'receta561.txt', 'receta563.txt', 'receta564.txt', 'receta566.txt', 'receta567.txt', 'receta568.txt', 'receta569.txt', 'receta570.txt', 'receta573.txt', 'receta574.txt', 'receta575.txt', 'receta576.txt', 'receta577.txt', 'receta578.txt', 'receta579.txt', 'receta580.txt', 'receta581.txt', 'receta582.txt', 'receta583.txt', 'receta584.txt', 'receta586.txt', 'receta587.txt', 'receta588.txt', 'receta589.txt', 'receta590.txt', 'receta591.txt', 'receta592.txt', 'receta813.txt', 'receta814.txt', 'receta815.txt', 'receta816.txt', 'receta817.txt', 'receta818.txt', 'receta819.txt', 'receta820.txt', 'receta941.txt', 'receta942.txt', 'receta943.txt', 'receta944.txt', 'receta945.txt', 'receta946.txt', 'receta947.txt', 'receta948.txt', 'receta949.txt', 'receta95.txt', 'receta950.txt', 'receta951.txt', 'receta952.txt', 'receta953.txt', 'receta954.txt', 'receta955.txt', 'receta956.txt', 'receta957.txt', 'receta958.txt', 'receta959.txt', 'receta960.txt', 'receta961.txt', 'receta962.txt', 'receta963.txt', 'receta964.txt', 'receta965.txt', 'receta966.txt', 'receta967.txt', 'receta968.txt', 'receta969.txt', 'receta970.txt', 'receta971.txt', 'receta972.txt', 'receta973.txt', 'receta974.txt', 'receta975.txt', 'receta976.txt', 'receta977.txt', 'receta978.txt', 'receta979.txt', 'receta980.txt', 'receta981.txt', 'receta982.txt', 'receta983.txt', 'receta984.txt', 'receta985.txt', 'receta986.txt', 'receta987.txt', 'receta988.txt', 'receta989.txt', 'receta990.txt']\n",
      "5./Interfaz/recetastextos/Carpeta Pescados/-----------------\n",
      "['receta1000.txt', 'receta1001.txt', 'receta1002.txt', 'receta1003.txt', 'receta1004.txt', 'receta1005.txt', 'receta1006.txt', 'receta1007.txt', 'receta1008.txt', 'receta1009.txt', 'receta1010.txt', 'receta1011.txt', 'receta1012.txt', 'receta1013.txt', 'receta1014.txt', 'receta1015.txt', 'receta1016.txt', 'receta1017.txt', 'receta1018.txt', 'receta1019.txt', 'receta1020.txt', 'receta1021.txt', 'receta1022.txt', 'receta1023.txt', 'receta1024.txt', 'receta1025.txt', 'receta1026.txt', 'receta1027.txt', 'receta1028.txt', 'receta1029.txt', 'receta1030.txt', 'receta1031.txt', 'receta1032.txt', 'receta1033.txt', 'receta1034.txt', 'receta1035.txt', 'receta1036.txt', 'receta1037.txt', 'receta1038.txt', 'receta1039.txt', 'receta1040.txt', 'receta11.txt', 'receta123.txt', 'receta1259.txt', 'receta1260.txt', 'receta1261.txt', 'receta1262.txt', 'receta1263.txt', 'receta1264.txt', 'receta1265.txt', 'receta1266.txt', 'receta1267.txt', 'receta1268.txt', 'receta1269.txt', 'receta1270.txt', 'receta1271.txt', 'receta1272.txt', 'receta1273.txt', 'receta1274.txt', 'receta1275.txt', 'receta1276.txt', 'receta1277.txt', 'receta1278.txt', 'receta1279.txt', 'receta1280.txt', 'receta1281.txt', 'receta1282.txt', 'receta1283.txt', 'receta1284.txt', 'receta1285.txt', 'receta1286.txt', 'receta1287.txt', 'receta1288.txt', 'receta1289.txt', 'receta1290.txt', 'receta1291.txt', 'receta1292.txt', 'receta1293.txt', 'receta1294.txt', 'receta1295.txt', 'receta1296.txt', 'receta1297.txt', 'receta1298.txt', 'receta1299.txt', 'receta1300.txt', 'receta1301.txt', 'receta1302.txt', 'receta1303.txt', 'receta1304.txt', 'receta1305.txt', 'receta1306.txt', 'receta1307.txt', 'receta1308.txt', 'receta1309.txt', 'receta1310.txt', 'receta1311.txt', 'receta181.txt', 'receta190.txt', 'receta194.txt', 'receta1992.txt', 'receta1993.txt', 'receta1994.txt', 'receta1995.txt', 'receta1996.txt', 'receta1997.txt', 'receta1998.txt', 'receta1999.txt', 'receta2000.txt', 'receta2001.txt', 'receta2002.txt', 'receta2003.txt', 'receta2004.txt', 'receta2005.txt', 'receta2006.txt', 'receta2007.txt', 'receta2008.txt', 'receta2009.txt', 'receta2010.txt', 'receta2011.txt', 'receta2012.txt', 'receta2013.txt', 'receta2014.txt', 'receta2015.txt', 'receta2016.txt', 'receta2017.txt', 'receta2018.txt', 'receta2019.txt', 'receta2020.txt', 'receta2021.txt', 'receta2022.txt', 'receta2023.txt', 'receta2024.txt', 'receta2025.txt', 'receta2026.txt', 'receta2027.txt', 'receta2028.txt', 'receta2029.txt', 'receta2030.txt', 'receta2031.txt', 'receta2032.txt', 'receta2033.txt', 'receta2034.txt', 'receta2035.txt', 'receta2036.txt', 'receta2037.txt', 'receta2038.txt', 'receta2039.txt', 'receta2040.txt', 'receta2041.txt', 'receta2042.txt', 'receta2043.txt', 'receta2044.txt', 'receta2045.txt', 'receta2046.txt', 'receta2047.txt', 'receta2048.txt', 'receta2049.txt', 'receta2050.txt', 'receta2051.txt', 'receta2052.txt', 'receta2053.txt', 'receta2054.txt', 'receta2055.txt', 'receta2056.txt', 'receta2057.txt', 'receta2058.txt', 'receta2059.txt', 'receta2060.txt', 'receta2061.txt', 'receta2062.txt', 'receta2063.txt', 'receta2064.txt', 'receta2065.txt', 'receta2066.txt', 'receta2067.txt', 'receta2068.txt', 'receta2069.txt', 'receta2070.txt', 'receta2071.txt', 'receta2072.txt', 'receta2073.txt', 'receta2074.txt', 'receta2075.txt', 'receta2076.txt', 'receta2077.txt', 'receta2078.txt', 'receta2079.txt', 'receta2080.txt', 'receta25.txt', 'receta297.txt', 'receta299.txt', 'receta301.txt', 'receta304.txt', 'receta323.txt', 'receta325.txt', 'receta332.txt', 'receta335.txt', 'receta336.txt', 'receta337.txt', 'receta338.txt', 'receta340.txt', 'receta480.txt', 'receta482.txt', 'receta484.txt', 'receta485.txt', 'receta488.txt', 'receta489.txt', 'receta490.txt', 'receta492.txt', 'receta493.txt', 'receta494.txt', 'receta495.txt', 'receta496.txt', 'receta497.txt', 'receta499.txt', 'receta500.txt', 'receta503.txt', 'receta504.txt', 'receta507.txt', 'receta508.txt', 'receta509.txt', 'receta513.txt', 'receta514.txt', 'receta519.txt', 'receta527.txt', 'receta530.txt', 'receta531.txt', 'receta537.txt', 'receta539.txt', 'receta596.txt', 'receta598.txt', 'receta601.txt', 'receta609.txt', 'receta611.txt', 'receta614.txt', 'receta617.txt', 'receta619.txt', 'receta620.txt', 'receta621.txt', 'receta622.txt', 'receta624.txt', 'receta625.txt', 'receta627.txt', 'receta629.txt', 'receta630.txt', 'receta7.txt', 'receta74.txt', 'receta81.txt', 'receta88.txt', 'receta991.txt', 'receta992.txt', 'receta993.txt', 'receta994.txt', 'receta995.txt', 'receta996.txt', 'receta997.txt', 'receta998.txt', 'receta999.txt']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6./Interfaz/recetastextos/Carpeta Platos Menores/-----------------\n",
      "['receta112.txt', 'receta1332.txt', 'receta1333.txt', 'receta1334.txt', 'receta1335.txt', 'receta1336.txt', 'receta1337.txt', 'receta1338.txt', 'receta1339.txt', 'receta1340.txt', 'receta1341.txt', 'receta1342.txt', 'receta1343.txt', 'receta1344.txt', 'receta1345.txt', 'receta1346.txt', 'receta1347.txt', 'receta1348.txt', 'receta1349.txt', 'receta1350.txt', 'receta1351.txt', 'receta1352.txt', 'receta1353.txt', 'receta1354.txt', 'receta1355.txt', 'receta1356.txt', 'receta1357.txt', 'receta1358.txt', 'receta1359.txt', 'receta1360.txt', 'receta1361.txt', 'receta1362.txt', 'receta1363.txt', 'receta1364.txt', 'receta1365.txt', 'receta1366.txt', 'receta1367.txt', 'receta1368.txt', 'receta1369.txt', 'receta1370.txt', 'receta1371.txt', 'receta1372.txt', 'receta1373.txt', 'receta1374.txt', 'receta1375.txt', 'receta1376.txt', 'receta1377.txt', 'receta1378.txt', 'receta1379.txt', 'receta1380.txt', 'receta1381.txt', 'receta1382.txt', 'receta1383.txt', 'receta1384.txt', 'receta1385.txt', 'receta1386.txt', 'receta1387.txt', 'receta1388.txt', 'receta1389.txt', 'receta1390.txt', 'receta1391.txt', 'receta1392.txt', 'receta1393.txt', 'receta1394.txt', 'receta1395.txt', 'receta1396.txt', 'receta1397.txt', 'receta1398.txt', 'receta1399.txt', 'receta14.txt', 'receta1400.txt', 'receta1401.txt', 'receta1402.txt', 'receta1403.txt', 'receta1404.txt', 'receta1405.txt', 'receta1406.txt', 'receta1407.txt', 'receta1408.txt', 'receta1409.txt', 'receta1410.txt', 'receta1411.txt', 'receta1412.txt', 'receta1413.txt', 'receta1414.txt', 'receta1415.txt', 'receta1416.txt', 'receta1417.txt', 'receta1418.txt', 'receta1419.txt', 'receta1420.txt', 'receta1421.txt', 'receta1422.txt', 'receta1423.txt', 'receta1424.txt', 'receta1425.txt', 'receta1426.txt', 'receta1427.txt', 'receta1428.txt', 'receta1429.txt', 'receta1430.txt', 'receta1431.txt', 'receta1432.txt', 'receta1433.txt', 'receta1434.txt', 'receta1435.txt', 'receta1436.txt', 'receta1437.txt', 'receta1438.txt', 'receta1439.txt', 'receta1440.txt', 'receta1441.txt', 'receta1442.txt', 'receta1443.txt', 'receta1444.txt', 'receta1445.txt', 'receta1446.txt', 'receta1447.txt', 'receta1448.txt', 'receta1449.txt', 'receta1450.txt', 'receta1451.txt', 'receta1452.txt', 'receta1453.txt', 'receta1454.txt', 'receta1455.txt', 'receta1456.txt', 'receta1457.txt', 'receta1458.txt', 'receta1459.txt', 'receta1460.txt', 'receta1461.txt', 'receta1462.txt', 'receta1463.txt', 'receta1464.txt', 'receta1465.txt', 'receta1466.txt', 'receta1467.txt', 'receta1468.txt', 'receta1469.txt', 'receta1470.txt', 'receta1471.txt', 'receta1472.txt', 'receta1473.txt', 'receta1474.txt', 'receta1475.txt', 'receta1476.txt', 'receta1477.txt', 'receta1478.txt', 'receta1479.txt', 'receta1480.txt', 'receta1481.txt', 'receta1482.txt', 'receta1483.txt', 'receta1484.txt', 'receta1485.txt', 'receta1486.txt', 'receta1487.txt', 'receta1488.txt', 'receta1489.txt', 'receta1490.txt', 'receta1491.txt', 'receta18.txt', 'receta1890.txt', 'receta1891.txt', 'receta1892.txt', 'receta1893.txt', 'receta1894.txt', 'receta1895.txt', 'receta1896.txt', 'receta1897.txt', 'receta1898.txt', 'receta1899.txt', 'receta1900.txt', 'receta1901.txt', 'receta1902.txt', 'receta1903.txt', 'receta1904.txt', 'receta1905.txt', 'receta1906.txt', 'receta1907.txt', 'receta1908.txt', 'receta1909.txt', 'receta1910.txt', 'receta1911.txt', 'receta1912.txt', 'receta1913.txt', 'receta1914.txt', 'receta1915.txt', 'receta1916.txt', 'receta1917.txt', 'receta1918.txt', 'receta1919.txt', 'receta1920.txt', 'receta1921.txt', 'receta1922.txt', 'receta1923.txt', 'receta1924.txt', 'receta1925.txt', 'receta1926.txt', 'receta1927.txt', 'receta1928.txt', 'receta1929.txt', 'receta1930.txt', 'receta1931.txt', 'receta1932.txt', 'receta1933.txt', 'receta1934.txt', 'receta1935.txt', 'receta1936.txt', 'receta1937.txt', 'receta1938.txt', 'receta1939.txt', 'receta1940.txt', 'receta1941.txt', 'receta1942.txt', 'receta1943.txt', 'receta1944.txt', 'receta1945.txt', 'receta1946.txt', 'receta1947.txt', 'receta1948.txt', 'receta1949.txt', 'receta1950.txt', 'receta1951.txt', 'receta1952.txt', 'receta1953.txt', 'receta1954.txt', 'receta1955.txt', 'receta1956.txt', 'receta1957.txt', 'receta1958.txt', 'receta1959.txt', 'receta1960.txt', 'receta1961.txt', 'receta1962.txt', 'receta1963.txt', 'receta1964.txt', 'receta1965.txt', 'receta1966.txt', 'receta1967.txt', 'receta1968.txt', 'receta1969.txt', 'receta1970.txt', 'receta1971.txt', 'receta1972.txt', 'receta1973.txt', 'receta1974.txt', 'receta1975.txt', 'receta1976.txt', 'receta1977.txt', 'receta1978.txt', 'receta1979.txt', 'receta1980.txt', 'receta1981.txt', 'receta1982.txt', 'receta1983.txt', 'receta1984.txt', 'receta1985.txt', 'receta1986.txt', 'receta1987.txt', 'receta1988.txt', 'receta1989.txt', 'receta1990.txt', 'receta1991.txt', 'receta2.txt', 'receta227.txt', 'receta27.txt', 'receta30.txt', 'receta38.txt', 'receta4.txt', 'receta47.txt', 'receta50.txt', 'receta53.txt', 'receta57.txt', 'receta60.txt', 'receta61.txt', 'receta69.txt', 'receta704.txt', 'receta705.txt', 'receta706.txt', 'receta711.txt', 'receta714.txt', 'receta716.txt', 'receta718.txt', 'receta72.txt', 'receta720.txt', 'receta721.txt', 'receta736.txt', 'receta737.txt', 'receta738.txt', 'receta739.txt', 'receta740.txt', 'receta741.txt', 'receta742.txt', 'receta743.txt', 'receta745.txt', 'receta746.txt', 'receta747.txt', 'receta748.txt', 'receta749.txt', 'receta75.txt', 'receta750.txt', 'receta751.txt', 'receta752.txt', 'receta754.txt', 'receta755.txt', 'receta757.txt', 'receta759.txt', 'receta760.txt', 'receta762.txt', 'receta763.txt', 'receta764.txt', 'receta765.txt', 'receta766.txt', 'receta767.txt', 'receta768.txt', 'receta769.txt', 'receta770.txt', 'receta771.txt', 'receta772.txt', 'receta773.txt', 'receta774.txt', 'receta775.txt', 'receta776.txt', 'receta777.txt', 'receta778.txt', 'receta779.txt', 'receta78.txt', 'receta780.txt', 'receta821.txt', 'receta822.txt', 'receta823.txt', 'receta824.txt', 'receta825.txt', 'receta826.txt', 'receta827.txt', 'receta828.txt', 'receta829.txt', 'receta830.txt', 'receta831.txt', 'receta832.txt', 'receta833.txt', 'receta834.txt', 'receta835.txt', 'receta836.txt', 'receta837.txt', 'receta838.txt', 'receta839.txt', 'receta840.txt', 'receta841.txt', 'receta842.txt', 'receta843.txt', 'receta844.txt', 'receta845.txt', 'receta846.txt', 'receta847.txt', 'receta848.txt', 'receta849.txt', 'receta850.txt', 'receta851.txt', 'receta852.txt', 'receta853.txt', 'receta854.txt', 'receta855.txt', 'receta856.txt', 'receta857.txt', 'receta858.txt', 'receta859.txt', 'receta860.txt', 'receta861.txt', 'receta862.txt', 'receta863.txt', 'receta864.txt', 'receta865.txt', 'receta866.txt', 'receta867.txt', 'receta868.txt', 'receta869.txt', 'receta87.txt', 'receta870.txt', 'receta9.txt']\n",
      "7./Interfaz/recetastextos/Carpeta Verduras/-----------------\n",
      "['receta1041.txt', 'receta1042.txt', 'receta1043.txt', 'receta1044.txt', 'receta1045.txt', 'receta1046.txt', 'receta1047.txt', 'receta1048.txt', 'receta1049.txt', 'receta1050.txt', 'receta1051.txt', 'receta1052.txt', 'receta1053.txt', 'receta1054.txt', 'receta1055.txt', 'receta1056.txt', 'receta1057.txt', 'receta1058.txt', 'receta1059.txt', 'receta1060.txt', 'receta1061.txt', 'receta1062.txt', 'receta1063.txt', 'receta1064.txt', 'receta1065.txt', 'receta1066.txt', 'receta1067.txt', 'receta1068.txt', 'receta1069.txt', 'receta1070.txt', 'receta1071.txt', 'receta1072.txt', 'receta1073.txt', 'receta1074.txt', 'receta1075.txt', 'receta1076.txt', 'receta1077.txt', 'receta1078.txt', 'receta1079.txt', 'receta1080.txt', 'receta1081.txt', 'receta1082.txt', 'receta1083.txt', 'receta1084.txt', 'receta1085.txt', 'receta1086.txt', 'receta1087.txt', 'receta1088.txt', 'receta1089.txt', 'receta1090.txt', 'receta1091.txt', 'receta1092.txt', 'receta1093.txt', 'receta1094.txt', 'receta1095.txt', 'receta1096.txt', 'receta1097.txt', 'receta1098.txt', 'receta1099.txt', 'receta1100.txt', 'receta1101.txt', 'receta1102.txt', 'receta1103.txt', 'receta1104.txt', 'receta1105.txt', 'receta1106.txt', 'receta1107.txt', 'receta1108.txt', 'receta1109.txt', 'receta1110.txt', 'receta1111.txt', 'receta1112.txt', 'receta1113.txt', 'receta1114.txt', 'receta1115.txt', 'receta1116.txt', 'receta1117.txt', 'receta1118.txt', 'receta1119.txt', 'receta1120.txt', 'receta1121.txt', 'receta1122.txt', 'receta1123.txt', 'receta1124.txt', 'receta1125.txt', 'receta1126.txt', 'receta1127.txt', 'receta1128.txt', 'receta1129.txt', 'receta1130.txt', 'receta1131.txt', 'receta1132.txt', 'receta1133.txt', 'receta1134.txt', 'receta1135.txt', 'receta1136.txt', 'receta119.txt', 'receta13.txt', 'receta1492.txt', 'receta1493.txt', 'receta1494.txt', 'receta1495.txt', 'receta1496.txt', 'receta1497.txt', 'receta1498.txt', 'receta1499.txt', 'receta1500.txt', 'receta1501.txt', 'receta1502.txt', 'receta1503.txt', 'receta1504.txt', 'receta1505.txt', 'receta1506.txt', 'receta1507.txt', 'receta1508.txt', 'receta1509.txt', 'receta1510.txt', 'receta1511.txt', 'receta1512.txt', 'receta1513.txt', 'receta1514.txt', 'receta1515.txt', 'receta1516.txt', 'receta1517.txt', 'receta1518.txt', 'receta1519.txt', 'receta1520.txt', 'receta1521.txt', 'receta1522.txt', 'receta1523.txt', 'receta1524.txt', 'receta1525.txt', 'receta1526.txt', 'receta1527.txt', 'receta1528.txt', 'receta1529.txt', 'receta1530.txt', 'receta1531.txt', 'receta1532.txt', 'receta1533.txt', 'receta1534.txt', 'receta1535.txt', 'receta1536.txt', 'receta1537.txt', 'receta1538.txt', 'receta1539.txt', 'receta1540.txt', 'receta1541.txt', 'receta1542.txt', 'receta1543.txt', 'receta1544.txt', 'receta1545.txt', 'receta1546.txt', 'receta1547.txt', 'receta1548.txt', 'receta17.txt', 'receta2143.txt', 'receta2144.txt', 'receta2145.txt', 'receta2146.txt', 'receta2147.txt', 'receta2148.txt', 'receta2149.txt', 'receta2150.txt', 'receta2151.txt', 'receta2152.txt', 'receta2153.txt', 'receta2154.txt', 'receta2155.txt', 'receta2156.txt', 'receta2157.txt', 'receta2158.txt', 'receta2159.txt', 'receta2160.txt', 'receta2161.txt', 'receta2162.txt', 'receta2163.txt', 'receta2164.txt', 'receta2165.txt', 'receta2166.txt', 'receta2167.txt', 'receta2168.txt', 'receta2169.txt', 'receta2170.txt', 'receta2171.txt', 'receta2172.txt', 'receta2173.txt', 'receta2174.txt', 'receta2175.txt', 'receta2176.txt', 'receta2177.txt', 'receta2178.txt', 'receta2179.txt', 'receta2180.txt', 'receta2181.txt', 'receta2182.txt', 'receta2183.txt', 'receta2184.txt', 'receta2185.txt', 'receta2186.txt', 'receta2187.txt', 'receta2188.txt', 'receta2189.txt', 'receta2190.txt', 'receta2191.txt', 'receta2192.txt', 'receta2193.txt', 'receta2194.txt', 'receta2195.txt', 'receta2196.txt', 'receta2197.txt', 'receta2198.txt', 'receta2199.txt', 'receta2200.txt', 'receta2201.txt', 'receta2202.txt', 'receta2203.txt', 'receta2204.txt', 'receta2205.txt', 'receta2206.txt', 'receta2207.txt', 'receta2208.txt', 'receta2209.txt', 'receta2210.txt', 'receta2211.txt', 'receta2212.txt', 'receta2213.txt', 'receta2214.txt', 'receta2215.txt', 'receta2216.txt', 'receta2217.txt', 'receta2218.txt', 'receta2219.txt', 'receta2220.txt', 'receta2221.txt', 'receta2222.txt', 'receta2223.txt', 'receta2224.txt', 'receta2225.txt', 'receta2226.txt', 'receta2227.txt', 'receta2228.txt', 'receta2229.txt', 'receta2230.txt', 'receta2231.txt', 'receta2232.txt', 'receta2233.txt', 'receta2234.txt', 'receta2235.txt', 'receta2236.txt', 'receta2237.txt', 'receta2238.txt', 'receta2239.txt', 'receta2240.txt', 'receta2241.txt', 'receta2242.txt', 'receta2243.txt', 'receta2244.txt', 'receta2245.txt', 'receta2246.txt', 'receta2247.txt', 'receta2248.txt', 'receta2249.txt', 'receta2250.txt', 'receta2251.txt', 'receta2252.txt', 'receta2253.txt', 'receta2254.txt', 'receta2255.txt', 'receta2256.txt', 'receta2257.txt', 'receta2258.txt', 'receta2259.txt', 'receta2260.txt', 'receta2261.txt', 'receta2262.txt', 'receta2263.txt', 'receta2264.txt', 'receta2265.txt', 'receta2266.txt', 'receta2267.txt', 'receta296.txt', 'receta339.txt', 'receta342.txt', 'receta343.txt', 'receta346.txt', 'receta347.txt', 'receta348.txt', 'receta349.txt', 'receta350.txt', 'receta352.txt', 'receta353.txt', 'receta354.txt', 'receta355.txt', 'receta356.txt', 'receta357.txt', 'receta36.txt', 'receta431.txt', 'receta433.txt', 'receta434.txt', 'receta435.txt', 'receta436.txt', 'receta438.txt', 'receta439.txt', 'receta440.txt', 'receta442.txt', 'receta446.txt', 'receta447.txt', 'receta448.txt', 'receta451.txt', 'receta454.txt', 'receta455.txt', 'receta456.txt', 'receta457.txt', 'receta459.txt', 'receta460.txt', 'receta462.txt', 'receta608.txt', 'receta64.txt', 'receta723.txt', 'receta724.txt', 'receta725.txt', 'receta726.txt', 'receta729.txt', 'receta730.txt', 'receta731.txt', 'receta732.txt', 'receta733.txt', 'receta734.txt', 'receta92.txt', 'receta94.txt']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>receta</th>\n",
       "      <th>clasif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ensal, arroz, mediterr, nea, veran, cociner, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[haz, arroz, band, 10, recet, pas, pas, mir, m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[arroz, mel, sep, gamb, alcachof, recet, cocin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[arroz, manit, cerd, set, recet, cocin, famil,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[paell, bacala, costr, aliol, recet, cocin, fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>[calabac, n, m, s, delici, com, recet, calabac...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>[fr, cali, tu, decid, com, delic, repoll, rece...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>[sop, past, alem, past, elab, 1, minut, d, as,...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>[recet, crem, calabaz, companion, jord, cruz, ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>[patat, mediterrane, andaluc, videorecet, entr...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1861 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 receta clasif\n",
       "0     [ensal, arroz, mediterr, nea, veran, cociner, ...      0\n",
       "1     [haz, arroz, band, 10, recet, pas, pas, mir, m...      0\n",
       "2     [arroz, mel, sep, gamb, alcachof, recet, cocin...      0\n",
       "3     [arroz, manit, cerd, set, recet, cocin, famil,...      0\n",
       "4     [paell, bacala, costr, aliol, recet, cocin, fa...      0\n",
       "...                                                 ...    ...\n",
       "1856  [calabac, n, m, s, delici, com, recet, calabac...      7\n",
       "1857  [fr, cali, tu, decid, com, delic, repoll, rece...      7\n",
       "1858  [sop, past, alem, past, elab, 1, minut, d, as,...      7\n",
       "1859  [recet, crem, calabaz, companion, jord, cruz, ...      7\n",
       "1860  [patat, mediterrane, andaluc, videorecet, entr...      7\n",
       "\n",
       "[1861 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df=pd.DataFrame()\n",
    "df['receta']=None\n",
    "df['clasif']=None\n",
    "procesarDocs=ProcesarDocumentos()\n",
    "listaTextosCarpeta=procesarDocs.lectura()\n",
    "\n",
    "for index,content in enumerate(listaTextosCarpeta):\n",
    "    for i in range(len(content)):\n",
    "        text=p.tratamientoTextos(listaTextosCarpeta[index][i])\n",
    "        df=df.append({'receta':text,'clasif':index},ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c330149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelos:\n",
    "    def __init__(self):\n",
    "        self.preprocesamiento()\n",
    "     \n",
    "    def preprocesamiento(self):\n",
    "        \n",
    "        #Se crea la funci√≥n que vectoriza los array de las recetas (calcula la frecuencia de las palabras) lo que\n",
    "        #convierte una lista de palabras en un array de frecuencias\n",
    "        self.vectorizer = CountVectorizer(analyzer = \"word\",  tokenizer = None, preprocessor = None,  stop_words = None,  max_features = 10000) \n",
    "\n",
    "        #Se separa el set de datos en datos de entrenamiento y de testeo. En este caso se divide en 80%-20%\n",
    "        #Creandose 4 variables -> \n",
    "        #X_train: Conjunto de recetas de entrenamiento (X_cv: en el testeo) \n",
    "        #Y_train: clasificaci√≥n de las recetas en los datos de entrenamiento (Y_cv: en el testeo)    \n",
    "        self.X_train, self.X_cv, self.Y_train, self.Y_cv = train_test_split(df[\"receta\"], df[\"clasif\"], test_size = 0.2, random_state=42)\n",
    "        self.Y_train=list(self.Y_train)\n",
    "\n",
    "        #Ahora vecrtorizamos X_train y X_cv para poder meterlo en el modelo de clasificaci√≥n\n",
    "        #Set de entrenamiento\n",
    "        arrayTemp=[]\n",
    "        for i,j in enumerate(self.X_train):           #El fit_transform funciona con string de frases enteras y autom√°ticamente tokeniza las palabras por lo que hayq ue volver a juntar las palabras en una frase\n",
    "            arrayTemp.append(\" \".join(j))\n",
    "        self.X_train = self.vectorizer.fit_transform(arrayTemp)\n",
    "        self.X_train = self.X_train.toarray()\n",
    "\n",
    "        #Set de testeo\n",
    "        arrayTemp=[]\n",
    "        for i,j in enumerate(self.X_cv):\n",
    "            arrayTemp.append(\" \".join(j))\n",
    "        self.X_cv = self.vectorizer.transform(arrayTemp)\n",
    "        self.X_cv = self.X_cv.toarray()\n",
    "        self.Y_train=list(self.Y_train)\n",
    "        self.Y_cv=list(self.Y_cv)\n",
    "        \n",
    "    def Entrenar_RF(self):\n",
    "        # Grid de hiperpar√°metros evaluados\n",
    "        # ==============================================================================\n",
    "        \n",
    "        print(self.X_train.shape)\n",
    "        param_grid = ParameterGrid(\n",
    "                        {'n_estimators': [1000],\n",
    "                         'max_features': [5, 7, 9],\n",
    "                         'max_depth'   : [None, 3, 10, 20],\n",
    "                         'criterion'   : ['gini', 'entropy']\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        # Loop para ajustar un modelo con cada combinaci√≥n de hiperpar√°metros\n",
    "        # ==============================================================================\n",
    "        resultados = {'params': [], 'oob_accuracy': []}\n",
    "\n",
    "        for params in param_grid:\n",
    "\n",
    "            modelo = RandomForestClassifier(\n",
    "                        oob_score    = True,\n",
    "                        n_jobs       = -1,\n",
    "                        random_state = 123,\n",
    "                        ** params\n",
    "                     )\n",
    "\n",
    "            modelo.fit(self.X_train, self.Y_train)\n",
    "\n",
    "            resultados['params'].append(params)\n",
    "            resultados['oob_accuracy'].append(modelo.oob_score_)\n",
    "            print(f\"Modelo: {params} \\u2713\")\n",
    "\n",
    "        # Resultados\n",
    "        # ==============================================================================\n",
    "        resultados = pd.DataFrame(resultados)\n",
    "        resultados = pd.concat([resultados, resultados['params'].apply(pd.Series)], axis=1)\n",
    "        resultados = resultados.sort_values('oob_accuracy', ascending=False)\n",
    "        resultados = resultados.drop(columns = 'params')\n",
    "        print(resultados.head(4))\n",
    "        \n",
    "        '''\n",
    "        self.forest = RandomForestClassifier() \n",
    "        self.forest = self.forest.fit(self.X_train, self.Y_train)\n",
    "\n",
    "        predictions = self.forest.predict(self.X_cv) \n",
    "        self.Y_cv=list(self.Y_cv)\n",
    "        print(\"Accuracy: \", accuracy_score(self.Y_cv, predictions))\n",
    "        '''\n",
    "        \n",
    "    def Entrenar_RF_CV(self):\n",
    "        # Grid de hiperpar√°metros evaluados\n",
    "        # ==============================================================================\n",
    "        param_grid = {'n_estimators': [150],\n",
    "                      'max_features': [5, 7, 9],\n",
    "                      'max_depth'   : [None, 3, 10, 20],\n",
    "                      'criterion'   : ['gini', 'entropy']\n",
    "                     }\n",
    "\n",
    "        # B√∫squeda por grid search con validaci√≥n cruzada\n",
    "        # ==============================================================================\n",
    "        grid = GridSearchCV(\n",
    "                estimator  = RandomForestClassifier(random_state = 123),\n",
    "                param_grid = param_grid,\n",
    "                scoring    = 'accuracy',\n",
    "                n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "                cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "                refit      = True,\n",
    "                verbose    = 0,\n",
    "                return_train_score = True\n",
    "               )\n",
    "\n",
    "        grid.fit(X = self.X_train, y = self.Y_train)\n",
    "\n",
    "        # Resultados\n",
    "        # ==============================================================================\n",
    "        resultados = pd.DataFrame(grid.cv_results_)\n",
    "        resultados.filter(regex = '(param*|mean_t|std_t)') \\\n",
    "            .drop(columns = 'params') \\\n",
    "            .sort_values('mean_test_score', ascending = False) \\\n",
    "            .head(4)\n",
    "        \n",
    "        # Mejores hiperpar√°metros por validaci√≥n cruzada\n",
    "        # ==============================================================================\n",
    "        print(\"----------------------------------------\")\n",
    "        print(\"Mejores hiperpar√°metros encontrados (cv)\")\n",
    "        print(\"----------------------------------------\")\n",
    "        print(grid.best_params_, \":\", grid.best_score_, grid.scoring)\n",
    "        \n",
    "        self.modelo_final = grid.best_estimator_\n",
    "        \n",
    "        '''\n",
    "        self.forest = RandomForestClassifier() \n",
    "        self.forest = self.forest.fit(self.X_train, self.Y_train)\n",
    "\n",
    "        predictions = self.forest.predict(self.X_cv) \n",
    "        self.Y_cv=list(self.Y_cv)\n",
    "        print(\"Accuracy: \", accuracy_score(self.Y_cv, predictions))\n",
    "        '''\n",
    "        \n",
    "        \n",
    "    def predecir_RF(self,txt):\n",
    "        \n",
    "        self.pred = self.vectorizer.transform(txt)\n",
    "        self.pred = self.pred.toarray()\n",
    "        predictions = self.forest.predict(self.pred) \n",
    "        #print(\"resultado: \" , predictions)\n",
    "        return list(predictions)\n",
    "    def predecir_Carpeta(self,txt):\n",
    "        \n",
    "        p=ProcesarDocumentos()\n",
    "        carpeta=p.resultadoStringCarpeta(txt)\n",
    "\n",
    "        resultados=[]\n",
    "        for i in range(len(carpeta)):\n",
    "            text=p.tratamientoTextos(carpeta[i])\n",
    "            hey=[\" \".join(text)]\n",
    "            resultados.append(self.predecir_RF(hey))\n",
    "        #print(\"Resultados: {}\".format(resultados))\n",
    "        \n",
    "        resultados=[]\n",
    "        for i in range(len(carpeta)):\n",
    "            text=p.tratamientoTextos(carpeta[i])\n",
    "            hey=\" \".join(text)\n",
    "            resultados.append(hey)\n",
    "        self.pred1 = self.vectorizer.transform(resultados)\n",
    "        self.pred1 = self.pred1.toarray()\n",
    "        predictions = self.forest.predict(self.pred1) \n",
    "        #print(\"resultado: \" , predictions)\n",
    "        return predictions\n",
    "        \n",
    "    def Entrenar_KNN(self):  \n",
    "        #self.preprocesamiento()\n",
    "        \n",
    "\n",
    "        vecinos = KNeighborsClassifier() \n",
    "        vecinos = vecinos.fit(self.X_train, self.Y_train)\n",
    "\n",
    "        predictions = vecinos.predict(self.X_cv) \n",
    "        self.Y_cv=list(self.Y_cv)\n",
    "        print(\"Accuracy: \", accuracy_score(self.Y_cv, predictions))\n",
    "\n",
    "    \n",
    "    def Entrenar_SVM(self):  \n",
    "        #self.preprocesamiento()\n",
    "        \n",
    "        #Create a svm Classifier\n",
    "        clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "        #Train the model using the training sets\n",
    "        clf.fit(self.X_train, self.Y_train)\n",
    "        \n",
    "\n",
    "        predictions = clf.predict(self.X_cv) \n",
    "        self.Y_cv=list(self.Y_cv)\n",
    "        print(\"Accuracy: \", accuracy_score(self.Y_cv, predictions))\n",
    "        \n",
    "        \n",
    "        cv=cross_val_score(clf, self.X_train, self.Y_train, cv=10)\n",
    "        \n",
    "        print(\"CV -> {}\".format(cv))\n",
    "        \n",
    "    def Entrenar_SVM_CV(self):\n",
    "        \n",
    "        \n",
    "        Cs = np.logspace(-6, -1, 10)\n",
    "        svc = svm.SVC()\n",
    "        clf = GridSearchCV(estimator=svc, param_grid=dict(C=Cs),\n",
    "                           n_jobs=-1)\n",
    "        clf.fit(self.X_train, self.Y_train)        \n",
    "\n",
    "        print(\"best score-> {}\".format(clf.best_score_))                                 \n",
    "\n",
    "        print(\"best estimator-> {}\".format(clf.best_estimator_.C))                            \n",
    "\n",
    "\n",
    "        # Prediction performance on test set is not as good as on train set\n",
    "        print(\"mi score\".format(clf.score(self.X_cv, self.Y_cv)))      \n",
    "\n",
    "    def Entrenar_Bayes(self):  \n",
    "        \n",
    "        #Create a svm Classifier\n",
    "        gaus = GaussianNB() # Linear Kernel\n",
    "\n",
    "        #Train the model using the training sets\n",
    "        gaus.fit(self.X_train, self.Y_train)\n",
    "        \n",
    "\n",
    "        predictions = gaus.predict(self.X_cv) \n",
    "        self.Y_cv=list(self.Y_cv)\n",
    "        print(\"Accuracy: \", accuracy_score(self.Y_cv, predictions))\n",
    "        \n",
    "        \n",
    "        cv=cross_val_score(gaus, self.X_train, self.Y_train, cv=10)\n",
    "        \n",
    "        print(\"CV -> {}\".format(cv))   \n",
    "        \n",
    "    \n",
    "    def regresionMultinomial(self):\n",
    "        \n",
    "        model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "        model.fit(self.X_train, self.Y_train)\n",
    "        \n",
    "\n",
    "        predictions = model.predict(self.X_cv) \n",
    "        self.Y_cv=list(self.Y_cv)\n",
    "        print(\"Accuracy: \", accuracy_score(self.Y_cv, predictions))\n",
    "        \n",
    "        \n",
    "        cv=cross_val_score(model, self.X_train, self.Y_train, cv=10)\n",
    "        \n",
    "        print(\"CV -> {}\".format(cv)) \n",
    "    def Entrenar_RedNeuronal(self):\n",
    "        \n",
    "        xtrain=[]\n",
    "        for i in range(len(self.X_train)):     \n",
    "            xtrain.append(list(self.X_train[i]))\n",
    "        #xtrain=np.array(xtrain)\n",
    "\n",
    "        xcv=[]\n",
    "        for i in range(len(self.X_cv)):     \n",
    "            xcv.append(list(self.X_cv[i]))\n",
    "        #xcv=np.array(xcv)\n",
    "        #Y_train=np.array(Y_train)\n",
    "        #Y_cv=np.array(Y_cv)\n",
    "\n",
    "\n",
    "        print(type(xtrain))\n",
    "        print(type(self.Y_train))\n",
    "        print(type(xcv))\n",
    "        print(type(self.Y_cv))\n",
    "        \n",
    "        \n",
    "        clear_session()\n",
    "        \n",
    "\n",
    "        #input_dim = xtrain.shape[1] #.shape[0]  # Number of features\n",
    "        input_dim= len(xtrain[0])\n",
    "        model = Sequential()\n",
    "        model.add(layers.Dense(7, input_dim=input_dim, activation='relu'))\n",
    "        model.add(layers.Dense(1, activation='sigmoid'))\n",
    "        '''\n",
    "        model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        loss_fn = tf.keras.losses.MeanSquaredError(reduction='sum_over_batch_size')\n",
    "        model.compile(loss=loss_fn, \n",
    "                       optimizer='adam', \n",
    "                       metrics=['accuracy'])\n",
    "        \n",
    "        print(model.summary())\n",
    "\n",
    "        xtrain2=[]\n",
    "        for i in range(len(xtrain)):\n",
    "            temp=[]\n",
    "            for j in range(len(xtrain[i])):\n",
    "                temp.append(int(xtrain[i][j]))\n",
    "            xtrain2.append(temp)\n",
    "        \n",
    "        xcv2=[]\n",
    "        for i in range(len(xcv)):\n",
    "            temp=[]\n",
    "            for j in range(len(xcv[i])):\n",
    "                temp.append(int(xcv[i][j]))\n",
    "            xcv2.append(temp)\n",
    "            \n",
    "        ytrain2=[]\n",
    "        for i in range(len(self.Y_train)):\n",
    "            ytrain2.append(int(self.Y_train[i]))\n",
    "            \n",
    "        ycv2=[]\n",
    "        for i in range(len(self.Y_cv)):\n",
    "            ycv2.append(int(self.Y_cv[i]))\n",
    "            \n",
    "        print(type(xtrain2[0][0]))    \n",
    "        self.xtrain2=xtrain2        \n",
    "        self.xtrain=xtrain\n",
    "        '''\n",
    "        history = model.fit(xtrain2, self.Y_train,\n",
    "                     epochs=10,\n",
    "                     verbose=False,\n",
    "                     validation_data=(xcv, self.Y_cv),\n",
    "                     batch_size=10)\n",
    "        '''\n",
    "        history = model.fit(xtrain2, ytrain2,\n",
    "                     epochs=10,\n",
    "                     verbose=False,\n",
    "                     validation_data=(xcv2, ycv2),\n",
    "                     batch_size=10)\n",
    "\n",
    "        \n",
    "        clear_session()\n",
    "        '''\n",
    "        loss, accuracy = model.evaluate(xtrain, self.Y_train, verbose=False)\n",
    "        print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "        loss, accuracy = model.evaluate(xcv, self.Y_cv, verbose=False)\n",
    "        print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "        '''\n",
    "        loss, accuracy = model.evaluate(xtrain2, ytrain2, verbose=False)\n",
    "        print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "        loss, accuracy = model.evaluate(xcv2, ycv2, verbose=False)\n",
    "        print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "\n",
    "    #return X_train, Y_train , X_cv , Y_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165b9ea9",
   "metadata": {},
   "source": [
    "## Probando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96b2262",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp1=modelos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff84345",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp1.regresionMultinomial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b649ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp1.Entrenar_Bayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe98e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp1.Entrenar_SVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40c644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp1.Entrenar_RF_CV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daf5cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp1.Entrenar_RF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e16c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp1.Entrenar_KNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6078296",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp1.modelo_final.predict(mp1.X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d6af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "hey=[\" \".join(df[df['clasif']==0]['receta'].iloc[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b869864",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp1.predecir_Carpeta(\"./Interfaz/testing/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b0f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3bca58dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelosTFIDF:\n",
    "    def __init__(self):\n",
    "        self.tfidf()\n",
    "    \n",
    "    def tfidf(self):\n",
    "        hola=[]\n",
    "        for i,j in enumerate(df['receta']):\n",
    "            hola.append(\" \".join(j))\n",
    "            \n",
    "        self.hola=hola\n",
    "        self.vectorizers= TfidfVectorizer(max_features=4000)    \n",
    "        self.vect = self.vectorizers.fit_transform(hola)\n",
    "        arr=self.vect.toarray()\n",
    "        variable=self.vectorizers.get_feature_names()\n",
    "        \n",
    "\n",
    "        variables=dict.fromkeys(variable,None)\n",
    "\n",
    "        tf1=pd.DataFrame(variables,index=[0])\n",
    "        for i in range(len(df['clasif'])):\n",
    "            tf1.loc[i]=arr[i]\n",
    "        \n",
    "        self.X_train, self.X_cv, self.Y_train, self.Y_cv = train_test_split(tf1, df['clasif'], test_size = 0.2, random_state=42)\n",
    "        self.Y_train=list(self.Y_train)\n",
    "        self.Y_cv=list(self.Y_cv)\n",
    "         \n",
    "  \n",
    "        \n",
    "    def Entrenar_RF(self):\n",
    "        # Grid de hiperpar√°metros evaluados\n",
    "        # ==============================================================================\n",
    "        \n",
    "        print(self.X_train.shape)\n",
    "        param_grid = ParameterGrid(\n",
    "                        {'n_estimators': [1000],\n",
    "                         'max_features': [5, 7, 9],\n",
    "                         'max_depth'   : [None, 3, 10, 20],\n",
    "                         'criterion'   : ['gini', 'entropy']\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        # Loop para ajustar un modelo con cada combinaci√≥n de hiperpar√°metros\n",
    "        # ==============================================================================\n",
    "        resultados = {'params': [], 'oob_accuracy': []}\n",
    "\n",
    "        for params in param_grid:\n",
    "\n",
    "            modelo = RandomForestClassifier(\n",
    "                        oob_score    = True,\n",
    "                        n_jobs       = -1,\n",
    "                        random_state = 123,\n",
    "                        ** params\n",
    "                     )\n",
    "\n",
    "            modelo.fit(self.X_train, self.Y_train)\n",
    "\n",
    "            resultados['params'].append(params)\n",
    "            resultados['oob_accuracy'].append(modelo.oob_score_)\n",
    "            print(f\"Modelo: {params} \\u2713\")\n",
    "\n",
    "        # Resultados\n",
    "        # ==============================================================================\n",
    "        resultados = pd.DataFrame(resultados)\n",
    "        resultados = pd.concat([resultados, resultados['params'].apply(pd.Series)], axis=1)\n",
    "        resultados = resultados.sort_values('oob_accuracy', ascending=False)\n",
    "        resultados = resultados.drop(columns = 'params')\n",
    "        print(resultados.head(4))\n",
    "        \n",
    "        '''\n",
    "        self.forest = RandomForestClassifier() \n",
    "        self.forest = self.forest.fit(self.X_train, self.Y_train)\n",
    "\n",
    "        predictions = self.forest.predict(self.X_cv) \n",
    "        self.Y_cv=list(self.Y_cv)\n",
    "        print(\"Accuracy: \", accuracy_score(self.Y_cv, predictions))\n",
    "        '''\n",
    "        \n",
    "    def Entrenar_RF_CV(self):\n",
    "        # Grid de hiperpar√°metros evaluados\n",
    "        # ==============================================================================\n",
    "        param_grid = {'n_estimators': [150],\n",
    "                      'max_features': [5, 7, 9],\n",
    "                      'max_depth'   : [None, 3, 10, 20],\n",
    "                      'criterion'   : ['gini', 'entropy']\n",
    "                     }\n",
    "\n",
    "        # B√∫squeda por grid search con validaci√≥n cruzada\n",
    "        # ==============================================================================\n",
    "        \n",
    "        grid = GridSearchCV(\n",
    "                estimator  = RandomForestClassifier(random_state = 123),\n",
    "                param_grid = param_grid,\n",
    "                scoring    = 'accuracy',\n",
    "                n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "                cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "                refit      = True,\n",
    "                verbose    = 0,\n",
    "                return_train_score = True\n",
    "               )\n",
    "\n",
    "        grid.fit(X = self.X_train, y = self.Y_train)\n",
    "\n",
    "        # Resultados\n",
    "        # ==============================================================================\n",
    "        resultados = pd.DataFrame(grid.cv_results_)\n",
    "        resultados.filter(regex = '(param*|mean_t|std_t)') \\\n",
    "            .drop(columns = 'params') \\\n",
    "            .sort_values('mean_test_score', ascending = False) \\\n",
    "            .head(4)\n",
    "        \n",
    "        # Mejores hiperpar√°metros por validaci√≥n cruzada\n",
    "        # ==============================================================================\n",
    "        print(\"----------------------------------------\")\n",
    "        print(\"Mejores hiperpar√°metros encontrados (cv)\")\n",
    "        print(\"----------------------------------------\")\n",
    "        print(grid.best_params_, \":\", grid.best_score_, grid.scoring)\n",
    "        \n",
    "        self.modelo_final = grid.best_estimator_\n",
    "        \n",
    "        '''\n",
    "        self.forest = RandomForestClassifier() \n",
    "        self.forest = self.forest.fit(self.X_train, self.Y_train)\n",
    "\n",
    "        predictions = self.forest.predict(self.X_cv) \n",
    "        self.Y_cv=list(self.Y_cv)\n",
    "        print(\"Accuracy: \", accuracy_score(self.Y_cv, predictions))\n",
    "        '''\n",
    "\n",
    "    def Entrenar_SVM(self):  \n",
    "        #self.preprocesamiento()\n",
    "        \n",
    "        #Create a svm Classifier\n",
    "        m_SVM = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "        #Train the model using the training sets\n",
    "        m_SVM.fit(self.X_train, self.Y_train)\n",
    "        \n",
    "\n",
    "        self.predictions = m_SVM.predict(self.X_cv) \n",
    "        self.Y_cv=list(self.Y_cv)\n",
    "        print(\"Accuracy: \", accuracy_score(self.Y_cv, self.predictions))\n",
    "        \n",
    "        \n",
    "        #cv=cross_val_score(m_SVM, self.X_train, self.Y_train, cv=10)\n",
    "        self.m_SVM=m_SVM\n",
    "        \n",
    "         #print(\"CV -> {}\".format(cv))\n",
    "        return self.m_SVM\n",
    "        \n",
    "    def Entrenar_SVM_CV(self):\n",
    "        \n",
    "        Cs = np.logspace(-6, -1, 10)\n",
    "        svc = svm.SVC()\n",
    "        m_SVM_CV = GridSearchCV(estimator=svc, param_grid=dict(C=Cs),\n",
    "                           n_jobs=-1)\n",
    "        m_SVM_CV.fit(self.X_train, self.Y_train)        \n",
    "\n",
    "        print(\"best score-> {}\".format(m_SVM_CV.best_score_))                                 \n",
    "\n",
    "        print(\"best estimator-> {}\".format(m_SVM_CV.best_estimator_.C))                            \n",
    "\n",
    "\n",
    "        # Prediction performance on test set is not as good as on train set\n",
    "        print(\"mi score\".format(m_SVM_CV.score(self.X_cv, self.Y_cv)))      \n",
    "\n",
    "    def Entrenar_Bayes(self):\n",
    "        \n",
    "        \n",
    "        #Create a svm Classifier\n",
    "        gaus = GaussianNB() # Linear Kernel\n",
    "\n",
    "        #Train the model using the training sets\n",
    "        gaus.fit(self.X_train, self.Y_train)\n",
    "        \n",
    "\n",
    "        predictions = gaus.predict(self.X_cv) \n",
    "        self.Y_cv=list(self.Y_cv)\n",
    "        print(\"Accuracy: \", accuracy_score(self.Y_cv, predictions))\n",
    "        \n",
    "        \n",
    "        cv=cross_val_score(gaus, self.X_train, self.Y_train, cv=10)\n",
    "        self.gaus=gaus\n",
    "        print(\"CV -> {}\".format(cv))   \n",
    "        \n",
    "    \n",
    "    def regresionMultinomial(self):\n",
    "        \n",
    "        M_mult = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "        M_mult.fit(self.X_train, self.Y_train)\n",
    "        \n",
    "        predictions = M_mult.predict(self.X_cv) \n",
    "        self.Y_cv=list(self.Y_cv)\n",
    "        print(\"Accuracy: \", accuracy_score(self.Y_cv, predictions))\n",
    "        \n",
    "        #cv=cross_val_score(M_mult, self.X_train, self.Y_train, cv=10)\n",
    "        self.M_mult=M_mult\n",
    "        #print(\"CV -> {}\".format(cv)) \n",
    "    \n",
    "    def predecir_RF(self,txt):\n",
    "        \n",
    "        self.pred = self.vectorizers.transform(txt)\n",
    "        self.pred = self.pred.toarray()\n",
    "        predictions = self.M_mult.predict(self.pred) \n",
    "        print(\"resultado: \" , predictions)\n",
    "        \n",
    "    def clasificar(self,modelo,txt):\n",
    "        \n",
    "        self.pred = self.vectorizers.transform(txt)\n",
    "        self.pred = self.pred.toarray()\n",
    "        predictions = modelo.predict(self.pred) \n",
    "        print(\"resultado: \" , predictions)\n",
    "    \n",
    "    def predecir_Carpeta(self,txt):\n",
    "        \n",
    "        p=ProcesarDocumentos()\n",
    "        carpeta=p.resultadoStringCarpeta(txt)\n",
    "\n",
    "        resultados=[]\n",
    "        for i in range(len(carpeta)):\n",
    "            text=p.tratamientoTextos(carpeta[i])\n",
    "            hey=[\" \".join(text)]\n",
    "            resultados.append(self.predecir_RF(hey))\n",
    "        #print(\"Resultados: {}\".format(resultados))\n",
    "        \n",
    "        resultados=[]\n",
    "        for i in range(len(carpeta)):\n",
    "            text=p.tratamientoTextos(carpeta[i])\n",
    "            hey=\" \".join(text)\n",
    "            resultados.append(hey)\n",
    "        self.pred1 = self.vect.transform(resultados)\n",
    "        self.pred1 = self.pred1.toarray()\n",
    "        predictions = self.M_mult.predict(self.pred1) \n",
    "        #print(\"resultado: \" , predictions)\n",
    "        return predictions\n",
    "        \n",
    "    def Entrenar_KNN(self):  \n",
    "        #self.preprocesamiento()\n",
    "        \n",
    "\n",
    "        vecinos = KNeighborsClassifier() \n",
    "        vecinos = vecinos.fit(self.X_train, self.Y_train)\n",
    "\n",
    "        predictions = vecinos.predict(self.X_cv) \n",
    "        self.Y_cv=list(self.Y_cv)\n",
    "        print(\"Accuracy: \", accuracy_score(self.Y_cv, predictions))\n",
    "        \n",
    "    \n",
    "    def Entrenar_RedNeuronal(self):\n",
    "        xtrain=[]\n",
    "        for i in range(len(self.X_train)):     \n",
    "            xtrain.append(list(self.X_train.iloc[i]))\n",
    "        #xtrain=np.array(xtrain)\n",
    "\n",
    "        xcv=[]\n",
    "        for i in range(len(self.X_cv)):     \n",
    "            xcv.append(list(self.X_cv.iloc[i]))\n",
    "        #xcv=np.array(xcv)\n",
    "        #Y_train=np.array(Y_train)\n",
    "        #Y_cv=np.array(Y_cv)\n",
    "\n",
    "\n",
    "        print(type(xtrain))\n",
    "        print(type(self.Y_train))\n",
    "        print(type(xcv))\n",
    "        print(type(self.Y_cv))\n",
    "        \n",
    "        \n",
    "        clear_session()\n",
    "        \n",
    "\n",
    "        #input_dim = xtrain.shape[1] #.shape[0]  # Number of features\n",
    "        input_dim= len(xtrain[0])\n",
    "        model = Sequential()\n",
    "        model.add(layers.Dense(100, input_dim=input_dim, activation='relu'))\n",
    "        model.add(layers.Dense(80, input_dim=100, activation='relu'))\n",
    "        model.add(layers.Dense(20, input_dim=80, activation='relu'))\n",
    "        model.add(layers.Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "        print(model.summary())\n",
    "        history = model.fit(xtrain, self.Y_train,\n",
    "                     epochs=1000,\n",
    "                     verbose=False,\n",
    "                     validation_data=(xcv, self.Y_cv),\n",
    "                     batch_size=10)\n",
    "\n",
    "        \n",
    "        clear_session()\n",
    "\n",
    "        loss, accuracy = model.evaluate(xtrain, self.Y_train, verbose=False)\n",
    "        print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "        loss, accuracy = model.evaluate(xcv, self.Y_cv, verbose=False)\n",
    "        print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "\n",
    "    def guardarModelo(self,modelo,nombre):\n",
    "        \n",
    "        joblib.dump(modelo, './Interfaz/modelos/{}.pkl'.format(nombre)) # Guardo el modelo.\n",
    "    \n",
    "    def cargarModelo(self,nombre):\n",
    "        \n",
    "        return joblib.load('./Interfaz/modelos/{}.pkl'.format(nombre))\n",
    "    def guardarVect(self,vect,nombre):\n",
    "        \n",
    "        joblib.dump(vect, './Interfaz/modelos/{}.pkl'.format(nombre)) # Guardo el modelo.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd31ea1c",
   "metadata": {},
   "source": [
    "## Probando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bed0ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tf=modelosTFIDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11b6ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tf.Entrenar_RF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "907c2587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8820375335120644\n"
     ]
    }
   ],
   "source": [
    "modelo1=m_tf.Entrenar_SVM()  #entrenamos y guardamos el modelo en una variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d3dacb72",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'modelosTFIDF' object has no attribute 'predictions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [75]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[1;32m----> 4\u001b[0m confusion_matrix \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mconfusion_matrix(m_tf\u001b[38;5;241m.\u001b[39mY_cv, \u001b[43mm_tf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictions\u001b[49m)\n\u001b[0;32m      6\u001b[0m cm_display \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mConfusionMatrixDisplay(confusion_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix, display_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArroz\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBebida\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCarne\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMarisco\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPasta\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPescados\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlatos menores\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVerduras\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      7\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'modelosTFIDF' object has no attribute 'predictions'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(m_tf.Y_cv, m_tf.predictions)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [\"Arroz\",\"Bebida\",\"Carne\",\"Marisco\",\"Pasta\",\"Pescados\",\"Platos menores\",\"Verduras\"])\n",
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "cm_display.plot(ax=ax)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('matrizconfusion.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7ea06ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m_tf.Y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f094bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m_tf.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1eea11cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'linear',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdf3256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hola=modelo1.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a6ce9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3900"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hola-100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8cc6529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tf.guardarModelo(modelo1,\"modelo2_SVM\")  #guardamos el modelo en formato plk en la direcci√≥n -> ./Interfaz/modelos/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d9166e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloImportado=m_tf.cargarModelo(\"modelo2_SVM\")  #cargamos un modelo externo y lo guardamos en una variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3ad33667",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectImportado=m_tf.guardarVect(m_tf.vectorizers,\"vectorizerPrueba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a819ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectImportado_=joblib.load('./Interfaz/modelos/{}.pkl'.format(\"vectorizerPrueba\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c140a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=vectImportado_.transform(m_tf.hola)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b42ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=vect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f6982600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.05049143, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.04191422, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a119c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloIportado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "393b2a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeloImportado.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb3bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hey=[\" \".join(df['receta'][400])]\n",
    "m_tf.clasificar(modelo1,hey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed28c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tf.Entrenar_Bayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ef526",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tf.regresionMultinomial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b8091",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tf.predecir_Carpeta(\"./Interfaz/Carpeta Testing/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e7f0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hola(hey):\n",
    "    string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bec36eb",
   "metadata": {},
   "source": [
    "### TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5eaf48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b982ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hola=[]\n",
    "for i,j in enumerate(df['receta']):\n",
    "    hola.append(\" \".join(j))\n",
    "vectorizer= TfidfVectorizer()    \n",
    "vect = vectorizer.fit_transform(hola)\n",
    "\n",
    "variable=vectorizer.get_feature_names()\n",
    "arr=vect.toarray()\n",
    "v=[]\n",
    "for i in df['clasif'].unique():\n",
    "    if i==0:\n",
    "        v.append(arr[:len(df[df['clasif']==i])])\n",
    "    elif i<max(df['clasif'].unique()):\n",
    "        v.append(arr[len(df[df['clasif']<=i-1]):len(df[df['clasif']<=i])])\n",
    "    else:\n",
    "        v.append(arr[len(df[df['clasif']==i-1]):])\n",
    "\n",
    "w=[]\n",
    "for i in range(len(v)):\n",
    "    w.append(sum(v[i]))\n",
    "    \n",
    "\n",
    "\n",
    "variables=dict.fromkeys(variable,None)\n",
    "    \n",
    "tf1=pd.DataFrame(variables,index=[0])\n",
    "for i in df['clasif'].unique():\n",
    "    tf1.loc[i]=w[i]\n",
    "\n",
    "tf1.index = pd.Series(['Arroz', 'Bebidas', 'Carnes','Marisco','Pasta','Pescados','PlatosMenores','Verduras'])\n",
    "tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03713614",
   "metadata": {},
   "outputs": [],
   "source": [
    "hola=[]\n",
    "for i,j in enumerate(df['receta']):\n",
    "    hola.append(\" \".join(j))\n",
    "vectorizers= TfidfVectorizer(max_features=4000)    \n",
    "vect = vectorizers.fit_transform(hola)\n",
    "\n",
    "variable=vectorizers.get_feature_names()\n",
    "arr=vect.toarray()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "variables=dict.fromkeys(variable,None)\n",
    "\n",
    "tf1=pd.DataFrame(variables,index=[0])\n",
    "for i in range(len(df['clasif'])):\n",
    "    tf1.loc[i]=arr[i]\n",
    "\n",
    "tf1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce6f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_cv, Y_train, Y_cv = train_test_split(tf1, df['clasif'], test_size = 0.3, random_state=42)\n",
    "Y_train=list(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac47c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier() \n",
    "forest = forest.fit(X_train, Y_train)\n",
    "\n",
    "predictions = forest.predict(X_cv) \n",
    "Y_cv=list(Y_cv)\n",
    "print(\"Accuracy: \", accuracy_score(Y_cv, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce96366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term(dict, search_index):\n",
    "    return list(dict.keys())[list(dict.values()).index(search_index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3ac10a",
   "metadata": {},
   "source": [
    "### Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad5646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4de485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# Gr√°ficos\n",
    "# ==============================================================================\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Modelado\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# Configuraci√≥n warnings\n",
    "# ==============================================================================\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e21e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_cv, Y_train, Y_cv = train_test_split(tf1, df['clasif'], test_size = 0.2, random_state=42)\n",
    "Y_train=list(Y_train)\n",
    "Y_cv=list(Y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9926ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7b5947",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565e3374",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ytrain=np.array(Y_train)\n",
    "ytest=np.array(Y_cv)\n",
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3dead0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e6861",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=[]\n",
    "for i in range(len(X_train)):     \n",
    "    xtrain.append(list(X_train.iloc[i]))\n",
    "#xtrain=np.array(xtrain)\n",
    "\n",
    "xcv=[]\n",
    "for i in range(len(X_cv)):     \n",
    "    xcv.append(list(X_cv.iloc[i]))\n",
    "#xcv=np.array(xcv)\n",
    "#Y_train=np.array(Y_train)\n",
    "#Y_cv=np.array(Y_cv)\n",
    "\n",
    "\n",
    "print(type(xtrain))\n",
    "print(type(Y_train))\n",
    "print(type(xcv))\n",
    "print(type(Y_cv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6ce433",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(m.xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d6852",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a574cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clear_session()\n",
    "\n",
    "\n",
    "#input_dim = xtrain.shape[1] #.shape[0]  # Number of features\n",
    "input_dim= len(xtrain[0])\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(6000, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0bf33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceab2968",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "loss_fn = tf.keras.losses.MeanSquaredError(reduction='sum_over_batch_size')\n",
    "model.compile(loss=loss_fn, \n",
    "               optimizer='adam', \n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f15d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbceec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7ab43d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "history = model.fit(xtrain, Y_train,\n",
    "                     epochs=2000,\n",
    "                     verbose=False,\n",
    "                     validation_data=(xcv, Y_cv),\n",
    "                     batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592419ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbaaf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(xtrain, Y_train,\n",
    "                     epochs=2000,\n",
    "                     verbose=False,\n",
    "                     validation_data=(xcv, Y_cv),\n",
    "                     batch_size=10)\n",
    "\n",
    "\n",
    "clear_session()\n",
    "\n",
    "loss, accuracy = model.evaluate(xtrain, Y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(xcv, Y_cv, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(xtrain)):\n",
    "    if i<len(xtrain)-1:\n",
    "        if len(xtrain[i])!=len(xtrain[i+1]):\n",
    "            print(\"hay algo mal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d0b78",
   "metadata": {},
   "source": [
    "### Prueba Red Neuronal manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069f927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class capa():\n",
    "    def __init__(self, n_neuronas_capa_anterior, n_neuronas, funcion_act):\n",
    "        self.funcion_act = funcion_act\n",
    "        self.b  = np.round(stats.truncnorm.rvs(-1, 1, loc=0, scale=1, size= n_neuronas).reshape(1,n_neuronas),3)\n",
    "        self.W  = np.round(stats.truncnorm.rvs(-1, 1, loc=0, scale=1, size= n_neuronas * n_neuronas_capa_anterior).reshape(n_neuronas_capa_anterior,n_neuronas),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e8932",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "sigmoid = (\n",
    "  lambda x:1 / (1 + np.exp(-x)),\n",
    "  lambda x:x * (1 - x)\n",
    "  )\n",
    "\n",
    "rango = np.linspace(-10,10).reshape([50,1])\n",
    "datos_sigmoide = sigmoid[0](rango)\n",
    "datos_sigmoide_derivada = sigmoid[1](rango)\n",
    "\n",
    "#Cremos los graficos\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize =(15,5))\n",
    "axes[0].plot(rango, datos_sigmoide)\n",
    "axes[1].plot(rango, datos_sigmoide_derivada)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c67cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivada_relu(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "relu = (\n",
    "  lambda x: x * (x > 0),\n",
    "  lambda x:derivada_relu(x)\n",
    "  )\n",
    "\n",
    "datos_relu = relu[0](rango)\n",
    "datos_relu_derivada = relu[1](rango)\n",
    "\n",
    "\n",
    "# Volvemos a definir rango que ha sido cambiado\n",
    "rango = np.linspace(-10,10).reshape([50,1])\n",
    "\n",
    "# Cremos los graficos\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize =(15,5))\n",
    "axes[0].plot(rango, datos_relu[:,0])\n",
    "axes[1].plot(rango, datos_relu_derivada[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc237fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numero de neuronas en cada capa. \n",
    "# El primer valor es el numero de columnas de la capa de entrada.\n",
    "neuronas = [2,4,8,1] \n",
    "\n",
    "# Funciones de activacion usadas en cada capa. \n",
    "funciones_activacion = [relu,relu, sigmoid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2126e41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_neuronal = []\n",
    "\n",
    "for paso in range(len(neuronas)-1):   \n",
    "    x = capa(neuronas[paso],neuronas[paso+1],funciones_activacion[paso])\n",
    "    red_neuronal.append(x)\n",
    "\n",
    "print(red_neuronal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_neuronal[0].W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac8882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  np.round(np.random.randn(20,2),3) # Ejemplo de vector de entrada\n",
    "\n",
    "z = X @ red_neuronal[0].W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = z + red_neuronal[0].b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431fb687",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = red_neuronal[0].funcion_act[0](z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cd0b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = [X]\n",
    "\n",
    "for num_capa in range(len(red_neuronal)):\n",
    "    z = output[-1] @ red_neuronal[num_capa].W + red_neuronal[num_capa].b\n",
    "    a = red_neuronal[num_capa].funcion_act[0](z)\n",
    "    output.append(a)\n",
    "\n",
    "print(output[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(Ypredich, Yreal):    \n",
    " # Calculamos el error\n",
    "    x = (np.array(Ypredich) - np.array(Yreal)) ** 2\n",
    "    x = np.mean(x)\n",
    " # Calculamos la derivada de la funcion\n",
    "    y = np.array(Ypredich) - np.array(Yreal)\n",
    "    return (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a03c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Y = [0] * 10 + [1] * 10\n",
    "shuffle(Y)\n",
    "Y = np.array(Y).reshape(len(Y),1)\n",
    "\n",
    "mse(output[-1], Y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backprop en la ultima capa\n",
    "a = output[-1]\n",
    "x = mse(a,Y)[1] * red_neuronal[-2].funcion_act[1](a)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f438772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_neuronal[-1].b = red_neuronal[-1].b - x.mean() * 0.01\n",
    "red_neuronal[-1].W = red_neuronal[-1].W - (output[-1].T @ x) * 0.01\n",
    "\n",
    "red_neuronal[-1].b\n",
    "red_neuronal[-1].W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca537f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el learning rate\n",
    "lr = 0.05\n",
    "\n",
    "# Creamos el indice inverso para ir de derecha a izquierda\n",
    "back = list(range(len(output)-1))\n",
    "back.reverse()\n",
    "\n",
    "# Creamos el vector delta donde meteremos los errores en cada capa\n",
    "delta = []\n",
    "\n",
    "for capa in back:\n",
    "  # Backprop #\n",
    "\n",
    "  # Guardamos los resultados de la ultima capa antes de usar backprop para poder usarlas en gradient descent\n",
    "    a = output[capa+1][1]\n",
    "\n",
    "  # Backprop en la ultima capa \n",
    "    if capa == back[0]:      \n",
    "        x = mse(a,Y)[1] * red_neuronal[capa].funcion_act[1](a)\n",
    "        delta.append(x)\n",
    "\n",
    "  # Backprop en el resto de capas \n",
    "    else:\n",
    "        x = delta[-1] @ W_temp * red_neuronal[capa].funcion_act[1](a)\n",
    "        delta.append(x)\n",
    "\n",
    "  # Guardamos los valores de W para poder usarlos en la iteracion siguiente\n",
    "    W_temp = red_neuronal[capa].W.transpose()\n",
    "\n",
    "  # Gradient Descent #\n",
    "\n",
    "  # Ajustamos los valores de los parametros de la capa\n",
    "    red_neuronal[capa].b = red_neuronal[capa].b - delta[-1].mean() * lr\n",
    "    red_neuronal[capa].W = red_neuronal[capa].W - (output[capa].T @ delta[-1]) * lr\n",
    "\n",
    "\n",
    "print('MSE: ' + str(mse(output[-1],Y)[0]) )\n",
    "print('Estimacion: ' + str(output[-1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f716186",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def circulo(num_datos = 100,R = 1, minimo = 0,maximo= 1):\n",
    "    pi = math.pi\n",
    "    r = R * np.sqrt(stats.truncnorm.rvs(minimo, maximo, size= num_datos)) * 10\n",
    "    theta = stats.truncnorm.rvs(minimo, maximo, size= num_datos) * 2 * pi *10\n",
    "\n",
    "    x = np.cos(theta) * r\n",
    "    y = np.sin(theta) * r\n",
    "\n",
    "    y = y.reshape((num_datos,1))\n",
    "    x = x.reshape((num_datos,1))\n",
    "\n",
    "  #Vamos a reducir el numero de elementos para que no cause un Overflow\n",
    "    x = np.round(x,3)\n",
    "    y = np.round(y,3)\n",
    "\n",
    "    df = np.column_stack([x,y])\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffeb7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_1 = circulo(num_datos = 150, R = 2)\n",
    "datos_2 = circulo(num_datos = 150, R = 0.5)\n",
    "X = np.concatenate([datos_1,datos_2])\n",
    "X = np.round(X,3)\n",
    "\n",
    "Y = [0] * 150 + [1] * 150\n",
    "Y = np.array(Y).reshape(len(Y),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7406f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "plt.scatter(X[0:150,0],X[0:150,1], c = \"b\")\n",
    "plt.scatter(X[150:300,0],X[150:300,1], c = \"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58a39d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenamiento(X,Y, red_neuronal, lr = 0.01):\n",
    "\n",
    "  # Output guardara el resultado de cada capa\n",
    "  # En la capa 1, el resultado es el valor de entrada\n",
    "    output = [X]\n",
    "\n",
    "    for num_capa in range(len(red_neuronal)):\n",
    "        \n",
    "        z = output[-1] @ red_neuronal[num_capa].W + red_neuronal[num_capa].b\n",
    "\n",
    "        a = red_neuronal[num_capa].funcion_act[0](z)\n",
    "\n",
    "    # Incluimos el resultado de la capa a output\n",
    "        output.append(a)\n",
    "\n",
    "  # Backpropagation\n",
    "\n",
    "    back = list(range(len(output)-1))\n",
    "    back.reverse()\n",
    "\n",
    "  # Guardaremos el error de la capa en delta  \n",
    "    delta = []\n",
    "\n",
    "    for capa in back:\n",
    "    # Backprop #delta\n",
    "\n",
    "        a = output[capa+1]\n",
    "\n",
    "        if capa == back[0]:\n",
    "            x = mse(a,Y)[1] * red_neuronal[capa].funcion_act[1](a)\n",
    "            delta.append(x)\n",
    "\n",
    "        else:\n",
    "            x = delta[-1] @ W_temp * red_neuronal[capa].funcion_act[1](a)\n",
    "            delta.append(x)\n",
    "\n",
    "        W_temp = red_neuronal[capa].W.transpose()\n",
    "\n",
    "    # Gradient Descent #\n",
    "        red_neuronal[capa].b = red_neuronal[capa].b - np.mean(delta[-1], axis = 0, keepdims = True) * lr\n",
    "        red_neuronal[capa].W = red_neuronal[capa].W - output[capa].transpose() @ delta[-1] * lr\n",
    "\n",
    "    return output[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5910605",
   "metadata": {},
   "outputs": [],
   "source": [
    "class capa():\n",
    "    \n",
    "    def __init__(self, n_neuronas_capa_anterior, n_neuronas, funcion_act):\n",
    "        \n",
    "        self.funcion_act = funcion_act\n",
    "        self.b  = np.round(stats.truncnorm.rvs(-1, 1, loc=0, scale=1, size= n_neuronas).reshape(1,n_neuronas),3)\n",
    "        self.W  = np.round(stats.truncnorm.rvs(-1, 1, loc=0, scale=1, size= n_neuronas * n_neuronas_capa_anterior).reshape(n_neuronas_capa_anterior,n_neuronas),3)\n",
    "\n",
    "neuronas = [2,4,8,1] \n",
    "funciones_activacion = [relu,relu, sigmoid]\n",
    "red_neuronal = []\n",
    "\n",
    "for paso in list(range(len(neuronas)-1)):\n",
    "    x = capa(neuronas[paso],neuronas[paso+1],funciones_activacion[paso])\n",
    "    red_neuronal.append(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed3094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "predicciones = []\n",
    "\n",
    "for epoch in range(0,1000):\n",
    "    ronda = entrenamiento(X = X ,Y = Y ,red_neuronal = red_neuronal, lr = 0.001)\n",
    "    predicciones.append(ronda)\n",
    "    temp = mse(np.round(predicciones[-1]),Y)[0]\n",
    "    error.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a00f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = list(range(0,1000))\n",
    "plt.plot(epoch, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3b441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
